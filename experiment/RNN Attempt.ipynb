{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd.variable import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "NUM_BODY_PARTS = 13\n",
    "TOTAL_FRAMES = 250\n",
    "BATCH_SIZE = 1\n",
    "# We have 250 frames. We are going to going to take the 17 body parts, \n",
    "# and turn it into 13 (remove eyes and ears). Then 13x2 (13 body parts, 2 vectors), gets shaped to\n",
    "# 26. We then take that 26, and convert it into a 250 x 26, each frame shows a body part.\n",
    "def from_motion_to_numpy_vector(motion):\n",
    "    # For now, we only take the first person. Later we can maybe try to feed in all people, or do batches of two\n",
    "    motion_vector = np.zeros((250, NUM_BODY_PARTS * 2))\n",
    "    if len(motion) < 250:\n",
    "        print(\"We need 250 frames.\")\n",
    "    for i, frame in enumerate(motion):\n",
    "        if len(frame) > 0 and i < TOTAL_FRAMES:\n",
    "            current_frame_data = frame\n",
    "            person0 = current_frame_data[0][1:]\n",
    "            current_frame_vector = np.zeros((NUM_BODY_PARTS, 2))\n",
    "            current_body_part_idx = 0\n",
    "            for body_part_data in person0:\n",
    "                body_part = body_part_data[0]\n",
    "                if body_part not in ['left_eye', 'left_ear', 'right_eye', 'right_ear']:\n",
    "                    current_frame_vector[current_body_part_idx] = body_part_data[1]\n",
    "                    current_body_part_idx = current_body_part_idx + 1\n",
    "            motion_vector[i] = current_frame_vector.reshape(NUM_BODY_PARTS * 2)\n",
    "    return motion_vector\n",
    "\n",
    "def from_numpy_vector_to_motion_coordinates(motion_vector):\n",
    "    # Reshape so each element in array is an a NUM_BODY_PARTS x 2 array that has coordinates\n",
    "    return motion_vector.reshape(TOTAL_FRAMES, NUM_BODY_PARTS, 2)\n",
    "\n",
    "class LetsDanceDataset(torch.utils.data.Dataset):\n",
    "    categories_hash = {'tango': 0, 'break': 1, 'swing': 2,'quickstep': 3,\n",
    "                  'foxtrot': 4,'pasodoble': 5,'tap': 6,'samba': 7,'flamenco': 8,\n",
    "                  'ballet': 9,'rumba': 10,'waltz': 11,'cha': 12,'latin': 13,\n",
    "                  'square': 14,'jive': 15}\n",
    "    \n",
    "    def __init__(self, root_dir):\n",
    "        super().__init__()\n",
    "        self.root_dir = root_dir\n",
    "        category = 'latin'\n",
    "\n",
    "        # For this first test, we are just using Latin dances\n",
    "        with open('./dance-frame-list.json') as f:\n",
    "            frames_index = json.load(f)\n",
    "                    \n",
    "        latin_dances = list(filter(lambda dance: dance[0] == 'latin' and dance[2] >= TOTAL_FRAMES, frames_index))\n",
    "        \n",
    "        self.data = np.zeros((len(latin_dances), TOTAL_FRAMES, NUM_BODY_PARTS * 2))\n",
    "        self.metadata = latin_dances\n",
    "        \n",
    "        for i, dance in enumerate(latin_dances):\n",
    "            [category, dance_id, frames] = dance\n",
    "            current_frame_path = \"{}{}/{}.json\".format(root_dir, category, dance_id)\n",
    "            with open(current_frame_path) as f:\n",
    "                motion = json.load(f)\n",
    "            self.data[i] = from_motion_to_numpy_vector(motion)\n",
    "            \n",
    "        f.close()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def getitem_metadata(self, index):\n",
    "        return self.metadata[index]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data = self.data[index]\n",
    "        with_batch_size = np.zeros((1, data.shape[0], data.shape[1]))\n",
    "        with_batch_size[0] = data\n",
    "        in_frames = with_batch_size\n",
    "        out_frames = np.zeros_like(in_frames)\n",
    "        out_frames[:-1] = in_frames[1:]\n",
    "        out_frames[-1] = in_frames[0]\n",
    "        return torch.from_numpy(in_frames), torch.from_numpy(out_frames)\n",
    "    \n",
    "dataloader = LetsDanceDataset('../densepose/full/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 250, 26])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader[1][0].shape\n",
    "# in_frames = motion[:num_batches * BATCH_SIZE * 250]\n",
    "# TODO\n",
    "# Bounding box idea, since the coordinates are all over the place, we should bound it to a certain box\n",
    "# try to clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# internally it works kinda like this\n",
    "current_frame_path = \"../densepose/full/latin/QmL0QYsctV0_030.json\"\n",
    "with open(current_frame_path) as f:\n",
    "    motion = json.load(f)\n",
    "        \n",
    "# for now, just return person 1 on the first frame, \n",
    "# just to see if it generates any stick figures\n",
    "# motion = np.array([pose_to_numpy(frame)[0].reshape(34) for frame in motion if len(frame) > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['person0',\n",
       "  ['nose', [1051.7425537109375, 74.26245880126953]],\n",
       "  ['left_eye', [1049.74853515625, 56.2840690612793]],\n",
       "  ['right_eye', [1045.760498046875, 56.2840690612793]],\n",
       "  ['left_ear', [1007.874755859375, 54.286468505859375]],\n",
       "  ['right_ear', [1011.8627319335938, 53.28767013549805]],\n",
       "  ['left_shoulder', [1033.796630859375, 122.204833984375]],\n",
       "  ['right_shoulder', [979.9589233398438, 107.22283935546875]],\n",
       "  ['left_elbow', [1061.7125244140625, 203.1075897216797]],\n",
       "  ['right_elbow', [1025.8206787109375, 195.1171875]],\n",
       "  ['left_wrist', [1098.601318359375, 213.0955810546875]],\n",
       "  ['right_wrist', [1099.5982666015625, 209.1003875732422]],\n",
       "  ['left_hip', [1032.7996826171875, 318.96832275390625]],\n",
       "  ['right_hip', [992.9197998046875, 317.9695129394531]],\n",
       "  ['left_knee', [1087.6343994140625, 465.7918395996094]],\n",
       "  ['right_knee', [1057.7244873046875, 466.7906494140625]],\n",
       "  ['left_ankle', [1047.7545166015625, 649.5709228515625]],\n",
       "  ['right_ankle', [1022.8296508789062, 663.5541381835938]]],\n",
       " ['person1',\n",
       "  ['nose', [669.4735717773438, 185.07545471191406]],\n",
       "  ['left_eye', [678.4266357421875, 177.0872039794922]],\n",
       "  ['right_eye', [660.5205078125, 177.0872039794922]],\n",
       "  ['left_ear', [691.35888671875, 181.08132934570312]],\n",
       "  ['right_ear', [646.593505859375, 185.07545471191406]],\n",
       "  ['left_shoulder', [716.2285766601562, 226.01524353027344]],\n",
       "  ['right_shoulder', [638.6351928710938, 253.97412109375]],\n",
       "  ['left_elbow', [740.1034545898438, 290.9197692871094]],\n",
       "  ['right_elbow', [628.6873168945312, 326.8669128417969]],\n",
       "  ['left_wrist', [753.03564453125, 351.8302001953125]],\n",
       "  ['right_wrist', [612.770751953125, 400.75823974609375]],\n",
       "  ['left_hip', [719.212890625, 359.8184509277344]],\n",
       "  ['right_hip', [669.4735717773438, 362.81402587890625]],\n",
       "  ['left_knee', [737.1190795898438, 470.6554260253906]],\n",
       "  ['right_knee', [681.4110107421875, 470.6554260253906]],\n",
       "  ['left_ankle', [735.1295166015625, 644.39990234375]],\n",
       "  ['right_ankle', [716.2285766601562, 582.4909057617188]]]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person0 = motion[0]\n",
    "person0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros((12, 2))\n",
    "a[0] = [1,2]\n",
    "a.reshape(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_points(points):\n",
    "    plt.xlim(0, 1980)\n",
    "    plt.ylim(-1000, 0)\n",
    "    reshaped = points.reshape(NUM_BODY_PARTS, 2)\n",
    "    x = reshaped[:,0]\n",
    "    y = reshaped[:,1]\n",
    "    plt.scatter(x, -y, s=10, marker='.',)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape:  torch.Size([1, 10, 10])\n",
      "Hidden:  (tensor([[[ 0.4691,  0.3007,  0.1901,  0.0947, -0.2166, -0.0910,  0.0847,\n",
      "           0.2070, -0.0761, -0.0679]],\n",
      "\n",
      "        [[ 0.0083, -0.1061,  0.2938, -0.1118, -0.0007, -0.0309, -0.3493,\n",
      "          -0.0033,  0.2563, -0.1784]]], grad_fn=<StackBackward>), tensor([[[ 1.0399,  0.3968,  0.2334,  0.3971, -0.2472, -0.2513,  0.1130,\n",
      "           0.3354, -0.1005, -0.3186]],\n",
      "\n",
      "        [[ 0.0150, -0.2194,  0.5644, -0.2261, -0.0015, -0.0572, -0.7213,\n",
      "          -0.0072,  0.5234, -0.3800]]], grad_fn=<StackBackward>))\n"
     ]
    }
   ],
   "source": [
    "# input_dim = 26\n",
    "# hidden_dim = 10\n",
    "# n_layers = 2\n",
    "# lstm_layer = nn.LSTM(input_dim, hidden_dim, n_layers, batch_first=True)\n",
    "# batch_size = 1\n",
    "# seq_len = 10\n",
    "\n",
    "# inp = torch.randn(batch_size, seq_len, input_dim)\n",
    "# hidden_state = torch.randn(n_layers, batch_size, hidden_dim)\n",
    "# cell_state = torch.randn(n_layers, batch_size, hidden_dim)\n",
    "# hidden = (hidden_state, cell_state)\n",
    "# out, hidden = lstm_layer(inp, hidden)\n",
    "# print(\"Output shape: \", out.shape)\n",
    "# print(\"Hidden: \", hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function next>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DanceModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(DanceModel, self).__init__()\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.hidden_dim = 500\n",
    "        self.n_layers = 15\n",
    "\n",
    "        #Defining the layers\n",
    "        # RNN Layer\n",
    "        self.lstm = nn.LSTM(input_size, self.hidden_dim, self.n_layers, batch_first=True)   \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(self.hidden_dim, output_size)\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        batch_size = x.size(0) # i am confused by batch size\n",
    "        x = x.float()\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
    "        hidden = (\n",
    "            torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device),\n",
    "            torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device))\n",
    "         # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_part_vector_size = NUM_BODY_PARTS * 2\n",
    "model = DanceModel(body_part_vector_size, body_part_vector_size)\n",
    "model.to(device)\n",
    "\n",
    "lr=0.005\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "experiment_name = 'experiments/{}/lr_{}'.format('rnn_test1',lr)\n",
    "\n",
    "os.makedirs(experiment_name, exist_ok=True)\n",
    "\n",
    "writer = SummaryWriter(log_dir=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/20] Step [0/67] Loss 336839.0659\n",
      "Epoch [0/20] Step [1/67] Loss 370929.6671\n",
      "Epoch [0/20] Step [2/67] Loss 366531.7084\n",
      "Epoch [0/20] Step [3/67] Loss 326088.1735\n",
      "Epoch [0/20] Step [4/67] Loss 314085.8424\n",
      "Epoch [0/20] Step [5/67] Loss 396395.6989\n",
      "Epoch [0/20] Step [6/67] Loss 439895.4363\n",
      "Epoch [0/20] Step [7/67] Loss 426482.7389\n",
      "Epoch [0/20] Step [8/67] Loss 622114.6107\n",
      "Epoch [0/20] Step [9/67] Loss 650408.1282\n",
      "Epoch [0/20] Step [10/67] Loss 381493.1081\n",
      "Epoch [0/20] Step [11/67] Loss 240450.0151\n",
      "Epoch [0/20] Step [12/67] Loss 615656.1330\n",
      "Epoch [0/20] Step [13/67] Loss 440793.6029\n",
      "Epoch [0/20] Step [14/67] Loss 619011.9182\n",
      "Epoch [0/20] Step [15/67] Loss 203690.0871\n",
      "Epoch [0/20] Step [16/67] Loss 459148.0891\n",
      "Epoch [0/20] Step [17/67] Loss 187177.9764\n",
      "Epoch [0/20] Step [18/67] Loss 568982.7875\n",
      "Epoch [0/20] Step [19/67] Loss 313267.9685\n",
      "Epoch [0/20] Step [20/67] Loss 310742.2918\n",
      "Epoch [0/20] Step [21/67] Loss 328269.8259\n",
      "Epoch [0/20] Step [22/67] Loss 231663.1119\n",
      "Epoch [0/20] Step [23/67] Loss 252539.3431\n",
      "Epoch [0/20] Step [24/67] Loss 232180.8989\n",
      "Epoch [0/20] Step [25/67] Loss 287170.7737\n",
      "Epoch [0/20] Step [26/67] Loss 192763.9935\n",
      "Epoch [0/20] Step [27/67] Loss 726382.0590\n",
      "Epoch [0/20] Step [28/67] Loss 279874.9399\n",
      "Epoch [0/20] Step [29/67] Loss 711464.5930\n",
      "Epoch [0/20] Step [30/67] Loss 479662.3436\n",
      "Epoch [0/20] Step [31/67] Loss 603321.0622\n",
      "Epoch [0/20] Step [32/67] Loss 520740.4173\n",
      "Epoch [0/20] Step [33/67] Loss 363617.8695\n",
      "Epoch [0/20] Step [34/67] Loss 507743.0623\n",
      "Epoch [0/20] Step [35/67] Loss 176904.6707\n",
      "Epoch [0/20] Step [36/67] Loss 649323.7843\n",
      "Epoch [0/20] Step [37/67] Loss 132818.4357\n",
      "Epoch [0/20] Step [38/67] Loss 408324.1392\n",
      "Epoch [0/20] Step [39/67] Loss 653866.3468\n",
      "Epoch [0/20] Step [40/67] Loss 304745.4673\n",
      "Epoch [0/20] Step [41/67] Loss 491757.6835\n",
      "Epoch [0/20] Step [42/67] Loss 379723.8601\n",
      "Epoch [0/20] Step [43/67] Loss 297650.6490\n",
      "Epoch [0/20] Step [44/67] Loss 178924.3782\n",
      "Epoch [0/20] Step [45/67] Loss 739390.8571\n",
      "Epoch [0/20] Step [46/67] Loss 197160.2486\n",
      "Epoch [0/20] Step [47/67] Loss 252833.5949\n",
      "Epoch [0/20] Step [48/67] Loss 399669.5844\n",
      "Epoch [0/20] Step [49/67] Loss 803554.1910\n",
      "Epoch [0/20] Step [50/67] Loss 200809.1960\n",
      "Epoch [0/20] Step [51/67] Loss 199658.1866\n",
      "Epoch [0/20] Step [52/67] Loss 597517.8388\n",
      "Epoch [0/20] Step [53/67] Loss 541299.3844\n",
      "Epoch [0/20] Step [54/67] Loss 654749.4464\n",
      "Epoch [0/20] Step [55/67] Loss 177933.5646\n",
      "Epoch [0/20] Step [56/67] Loss 157723.0142\n",
      "Epoch [0/20] Step [57/67] Loss 271472.9640\n",
      "Epoch [0/20] Step [58/67] Loss 469133.2085\n",
      "Epoch [0/20] Step [59/67] Loss 387360.9608\n",
      "Epoch [0/20] Step [60/67] Loss 319200.3447\n",
      "Epoch [0/20] Step [61/67] Loss 502220.8242\n",
      "Epoch [0/20] Step [62/67] Loss 488505.2694\n",
      "Epoch [0/20] Step [63/67] Loss 419602.4132\n",
      "Epoch [0/20] Step [64/67] Loss 182896.3327\n",
      "Epoch [0/20] Step [65/67] Loss 135387.4561\n",
      "Epoch [0/20] Step [66/67] Loss 222611.2580\n",
      "Epoch [1/20] Step [0/67] Loss 257963.9528\n",
      "Epoch [1/20] Step [1/67] Loss 283326.3092\n",
      "Epoch [1/20] Step [2/67] Loss 278205.4896\n",
      "Epoch [1/20] Step [3/67] Loss 241858.7940\n",
      "Epoch [1/20] Step [4/67] Loss 232585.6256\n",
      "Epoch [1/20] Step [5/67] Loss 303159.1397\n",
      "Epoch [1/20] Step [6/67] Loss 347656.0139\n",
      "Epoch [1/20] Step [7/67] Loss 339689.7840\n",
      "Epoch [1/20] Step [8/67] Loss 502244.1276\n",
      "Epoch [1/20] Step [9/67] Loss 527324.3375\n",
      "Epoch [1/20] Step [10/67] Loss 290623.8376\n",
      "Epoch [1/20] Step [11/67] Loss 174780.8608\n",
      "Epoch [1/20] Step [12/67] Loss 498673.0987\n",
      "Epoch [1/20] Step [13/67] Loss 335792.1556\n",
      "Epoch [1/20] Step [14/67] Loss 496936.6021\n",
      "Epoch [1/20] Step [15/67] Loss 139889.6050\n",
      "Epoch [1/20] Step [16/67] Loss 358901.6102\n",
      "Epoch [1/20] Step [17/67] Loss 122762.7279\n",
      "Epoch [1/20] Step [18/67] Loss 455611.5420\n",
      "Epoch [1/20] Step [19/67] Loss 235992.2238\n",
      "Epoch [1/20] Step [20/67] Loss 235524.2910\n",
      "Epoch [1/20] Step [21/67] Loss 247383.1260\n",
      "Epoch [1/20] Step [22/67] Loss 162069.3313\n",
      "Epoch [1/20] Step [23/67] Loss 191505.4724\n",
      "Epoch [1/20] Step [24/67] Loss 166944.9758\n",
      "Epoch [1/20] Step [25/67] Loss 208998.6259\n",
      "Epoch [1/20] Step [26/67] Loss 130382.9645\n",
      "Epoch [1/20] Step [27/67] Loss 592004.1281\n",
      "Epoch [1/20] Step [28/67] Loss 201815.1361\n",
      "Epoch [1/20] Step [29/67] Loss 579723.4964\n",
      "Epoch [1/20] Step [30/67] Loss 387657.7951\n",
      "Epoch [1/20] Step [31/67] Loss 485549.0320\n",
      "Epoch [1/20] Step [32/67] Loss 412086.8347\n",
      "Epoch [1/20] Step [33/67] Loss 272657.7269\n",
      "Epoch [1/20] Step [34/67] Loss 402813.8372\n",
      "Epoch [1/20] Step [35/67] Loss 116440.3775\n",
      "Epoch [1/20] Step [36/67] Loss 526977.8416\n",
      "Epoch [1/20] Step [37/67] Loss 80277.9533\n",
      "Epoch [1/20] Step [38/67] Loss 316808.1228\n",
      "Epoch [1/20] Step [39/67] Loss 529629.5215\n",
      "Epoch [1/20] Step [40/67] Loss 219625.0300\n",
      "Epoch [1/20] Step [41/67] Loss 387141.6416\n",
      "Epoch [1/20] Step [42/67] Loss 294151.5990\n",
      "Epoch [1/20] Step [43/67] Loss 218395.9377\n",
      "Epoch [1/20] Step [44/67] Loss 117002.3618\n",
      "Epoch [1/20] Step [45/67] Loss 610108.7866\n",
      "Epoch [1/20] Step [46/67] Loss 134476.3719\n",
      "Epoch [1/20] Step [47/67] Loss 181241.6467\n",
      "Epoch [1/20] Step [48/67] Loss 305856.0498\n",
      "Epoch [1/20] Step [49/67] Loss 667291.9922\n",
      "Epoch [1/20] Step [50/67] Loss 137390.9284\n",
      "Epoch [1/20] Step [51/67] Loss 136945.3279\n",
      "Epoch [1/20] Step [52/67] Loss 484758.0896\n",
      "Epoch [1/20] Step [53/67] Loss 437722.1068\n",
      "Epoch [1/20] Step [54/67] Loss 532817.3061\n",
      "Epoch [1/20] Step [55/67] Loss 117554.3272\n",
      "Epoch [1/20] Step [56/67] Loss 114336.8849\n",
      "Epoch [1/20] Step [57/67] Loss 192425.4376\n",
      "Epoch [1/20] Step [58/67] Loss 362488.8464\n",
      "Epoch [1/20] Step [59/67] Loss 297366.8137\n",
      "Epoch [1/20] Step [60/67] Loss 234026.1803\n",
      "Epoch [1/20] Step [61/67] Loss 398065.1155\n",
      "Epoch [1/20] Step [62/67] Loss 385625.0293\n",
      "Epoch [1/20] Step [63/67] Loss 324567.1610\n",
      "Epoch [1/20] Step [64/67] Loss 123997.5773\n",
      "Epoch [1/20] Step [65/67] Loss 85940.6345\n",
      "Epoch [1/20] Step [66/67] Loss 157589.5327\n",
      "Epoch [2/20] Step [0/67] Loss 194567.5917\n",
      "Epoch [2/20] Step [1/67] Loss 212563.1862\n",
      "Epoch [2/20] Step [2/67] Loss 205296.5210\n",
      "Epoch [2/20] Step [3/67] Loss 173283.8623\n",
      "Epoch [2/20] Step [4/67] Loss 166662.2250\n",
      "Epoch [2/20] Step [5/67] Loss 226042.8962\n",
      "Epoch [2/20] Step [6/67] Loss 270347.3069\n",
      "Epoch [2/20] Step [7/67] Loss 268298.1414\n",
      "Epoch [2/20] Step [8/67] Loss 399403.7394\n",
      "Epoch [2/20] Step [9/67] Loss 421207.8446\n",
      "Epoch [2/20] Step [10/67] Loss 216291.3507\n",
      "Epoch [2/20] Step [11/67] Loss 124972.1450\n",
      "Epoch [2/20] Step [12/67] Loss 399646.6329\n",
      "Epoch [2/20] Step [13/67] Loss 249598.1404\n",
      "Epoch [2/20] Step [14/67] Loss 392351.3620\n",
      "Epoch [2/20] Step [15/67] Loss 91500.5661\n",
      "Epoch [2/20] Step [16/67] Loss 274795.7817\n",
      "Epoch [2/20] Step [17/67] Loss 74315.0495\n",
      "Epoch [2/20] Step [18/67] Loss 358752.2151\n",
      "Epoch [2/20] Step [19/67] Loss 173801.4486\n",
      "Epoch [2/20] Step [20/67] Loss 175390.2797\n",
      "Epoch [2/20] Step [21/67] Loss 182218.4508\n",
      "Epoch [2/20] Step [22/67] Loss 108163.0466\n",
      "Epoch [2/20] Step [23/67] Loss 145527.2220\n",
      "Epoch [2/20] Step [24/67] Loss 117698.8886\n",
      "Epoch [2/20] Step [25/67] Loss 146443.5384\n",
      "Epoch [2/20] Step [26/67] Loss 83561.8945\n",
      "Epoch [2/20] Step [27/67] Loss 476611.9556\n",
      "Epoch [2/20] Step [28/67] Loss 140094.5478\n",
      "Epoch [2/20] Step [29/67] Loss 465440.7640\n",
      "Epoch [2/20] Step [30/67] Loss 311204.1611\n",
      "Epoch [2/20] Step [31/67] Loss 383913.8597\n",
      "Epoch [2/20] Step [32/67] Loss 319450.3291\n",
      "Epoch [2/20] Step [33/67] Loss 197751.0559\n",
      "Epoch [2/20] Step [34/67] Loss 313212.3938\n",
      "Epoch [2/20] Step [35/67] Loss 71069.8973\n",
      "Epoch [2/20] Step [36/67] Loss 420973.1499\n",
      "Epoch [2/20] Step [37/67] Loss 43089.0898\n",
      "Epoch [2/20] Step [38/67] Loss 240870.4259\n",
      "Epoch [2/20] Step [39/67] Loss 421941.0447\n",
      "Epoch [2/20] Step [40/67] Loss 151098.7225\n",
      "Epoch [2/20] Step [41/67] Loss 297946.0104\n",
      "Epoch [2/20] Step [42/67] Loss 222882.4126\n",
      "Epoch [2/20] Step [43/67] Loss 154117.1864\n",
      "Epoch [2/20] Step [44/67] Loss 70500.7022\n",
      "Epoch [2/20] Step [45/67] Loss 496903.9572\n",
      "Epoch [2/20] Step [46/67] Loss 86610.8248\n",
      "Epoch [2/20] Step [47/67] Loss 124721.7813\n",
      "Epoch [2/20] Step [48/67] Loss 227577.6494\n",
      "Epoch [2/20] Step [49/67] Loss 548355.1350\n",
      "Epoch [2/20] Step [50/67] Loss 88697.3374\n",
      "Epoch [2/20] Step [51/67] Loss 89638.3773\n",
      "Epoch [2/20] Step [52/67] Loss 387176.5150\n",
      "Epoch [2/20] Step [53/67] Loss 350482.1685\n",
      "Epoch [2/20] Step [54/67] Loss 427347.4688\n",
      "Epoch [2/20] Step [55/67] Loss 71797.4931\n",
      "Epoch [2/20] Step [56/67] Loss 85387.5432\n",
      "Epoch [2/20] Step [57/67] Loss 129397.3514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20] Step [58/67] Loss 273049.3223\n",
      "Epoch [2/20] Step [59/67] Loss 222922.6422\n",
      "Epoch [2/20] Step [60/67] Loss 164911.0106\n",
      "Epoch [2/20] Step [61/67] Loss 310052.8007\n",
      "Epoch [2/20] Step [62/67] Loss 297732.0075\n",
      "Epoch [2/20] Step [63/67] Loss 244313.7010\n",
      "Epoch [2/20] Step [64/67] Loss 79299.7464\n",
      "Epoch [2/20] Step [65/67] Loss 50178.9488\n",
      "Epoch [2/20] Step [66/67] Loss 107577.3899\n",
      "Epoch [3/20] Step [0/67] Loss 144438.5620\n",
      "Epoch [3/20] Step [1/67] Loss 157082.2542\n",
      "Epoch [3/20] Step [2/67] Loss 146243.6891\n",
      "Epoch [3/20] Step [3/67] Loss 118645.3903\n",
      "Epoch [3/20] Step [4/67] Loss 114469.2041\n",
      "Epoch [3/20] Step [5/67] Loss 163186.3729\n",
      "Epoch [3/20] Step [6/67] Loss 205933.8186\n",
      "Epoch [3/20] Step [7/67] Loss 210229.3886\n",
      "Epoch [3/20] Step [8/67] Loss 311602.8020\n",
      "Epoch [3/20] Step [9/67] Loss 330053.1798\n",
      "Epoch [3/20] Step [10/67] Loss 156489.4917\n",
      "Epoch [3/20] Step [11/67] Loss 88971.3622\n",
      "Epoch [3/20] Step [12/67] Loss 316695.1697\n",
      "Epoch [3/20] Step [13/67] Loss 180461.8421\n",
      "Epoch [3/20] Step [14/67] Loss 303305.6969\n",
      "Epoch [3/20] Step [15/67] Loss 56414.1174\n",
      "Epoch [3/20] Step [16/67] Loss 204746.4259\n",
      "Epoch [3/20] Step [17/67] Loss 39815.3105\n",
      "Epoch [3/20] Step [18/67] Loss 276364.1311\n",
      "Epoch [3/20] Step [19/67] Loss 124537.8490\n",
      "Epoch [3/20] Step [20/67] Loss 128187.0308\n",
      "Epoch [3/20] Step [21/67] Loss 130711.1315\n",
      "Epoch [3/20] Step [22/67] Loss 67928.0596\n",
      "Epoch [3/20] Step [23/67] Loss 112508.7380\n",
      "Epoch [3/20] Step [24/67] Loss 82533.8991\n",
      "Epoch [3/20] Step [25/67] Loss 97505.8472\n",
      "Epoch [3/20] Step [26/67] Loss 50367.3881\n",
      "Epoch [3/20] Step [27/67] Loss 378876.2365\n",
      "Epoch [3/20] Step [28/67] Loss 93291.5307\n",
      "Epoch [3/20] Step [29/67] Loss 367739.2209\n",
      "Epoch [3/20] Step [30/67] Loss 248862.7630\n",
      "Epoch [3/20] Step [31/67] Loss 297230.8531\n",
      "Epoch [3/20] Step [32/67] Loss 241594.7156\n",
      "Epoch [3/20] Step [33/67] Loss 137609.7041\n",
      "Epoch [3/20] Step [34/67] Loss 237593.2913\n",
      "Epoch [3/20] Step [35/67] Loss 39144.6800\n",
      "Epoch [3/20] Step [36/67] Loss 330307.7580\n",
      "Epoch [3/20] Step [37/67] Loss 19648.8171\n",
      "Epoch [3/20] Step [38/67] Loss 179262.5951\n",
      "Epoch [3/20] Step [39/67] Loss 329925.6148\n",
      "Epoch [3/20] Step [40/67] Loss 98019.3523\n",
      "Epoch [3/20] Step [41/67] Loss 222982.1357\n",
      "Epoch [3/20] Step [42/67] Loss 164391.6181\n",
      "Epoch [3/20] Step [43/67] Loss 103386.3195\n",
      "Epoch [3/20] Step [44/67] Loss 37976.6734\n",
      "Epoch [3/20] Step [45/67] Loss 398953.1556\n",
      "Epoch [3/20] Step [46/67] Loss 52044.2183\n",
      "Epoch [3/20] Step [47/67] Loss 81881.2335\n",
      "Epoch [3/20] Step [48/67] Loss 163677.9080\n",
      "Epoch [3/20] Step [49/67] Loss 446274.6826\n",
      "Epoch [3/20] Step [50/67] Loss 53267.1536\n",
      "Epoch [3/20] Step [51/67] Loss 56379.3614\n",
      "Epoch [3/20] Step [52/67] Loss 303776.2490\n",
      "Epoch [3/20] Step [53/67] Loss 278745.5019\n",
      "Epoch [3/20] Step [54/67] Loss 337709.7948\n",
      "Epoch [3/20] Step [55/67] Loss 39183.6619\n",
      "Epoch [3/20] Step [56/67] Loss 69227.5243\n",
      "Epoch [3/20] Step [57/67] Loss 81318.7928\n",
      "Epoch [3/20] Step [58/67] Loss 200215.0624\n",
      "Epoch [3/20] Step [59/67] Loss 163034.9168\n",
      "Epoch [3/20] Step [60/67] Loss 110960.1931\n",
      "Epoch [3/20] Step [61/67] Loss 237547.1444\n",
      "Epoch [3/20] Step [62/67] Loss 223914.9438\n",
      "Epoch [3/20] Step [63/67] Loss 177823.4366\n",
      "Epoch [3/20] Step [64/67] Loss 47333.0970\n",
      "Epoch [3/20] Step [65/67] Loss 26428.6973\n",
      "Epoch [3/20] Step [66/67] Loss 71290.3289\n",
      "Epoch [4/20] Step [0/67] Loss 105995.5327\n",
      "Epoch [4/20] Step [1/67] Loss 115743.9155\n",
      "Epoch [4/20] Step [2/67] Loss 99712.7423\n",
      "Epoch [4/20] Step [3/67] Loss 76614.3882\n",
      "Epoch [4/20] Step [4/67] Loss 74593.2878\n",
      "Epoch [4/20] Step [5/67] Loss 113365.3521\n",
      "Epoch [4/20] Step [6/67] Loss 152994.4706\n",
      "Epoch [4/20] Step [7/67] Loss 164097.3979\n",
      "Epoch [4/20] Step [8/67] Loss 238107.1995\n",
      "Epoch [4/20] Step [9/67] Loss 253260.6924\n",
      "Epoch [4/20] Step [10/67] Loss 110041.6309\n",
      "Epoch [4/20] Step [11/67] Loss 65301.9339\n",
      "Epoch [4/20] Step [12/67] Loss 249223.9845\n",
      "Epoch [4/20] Step [13/67] Loss 127840.6620\n",
      "Epoch [4/20] Step [14/67] Loss 229216.0027\n",
      "Epoch [4/20] Step [15/67] Loss 33134.6894\n",
      "Epoch [4/20] Step [16/67] Loss 147777.9538\n",
      "Epoch [4/20] Step [17/67] Loss 17803.7454\n",
      "Epoch [4/20] Step [18/67] Loss 207754.1252\n",
      "Epoch [4/20] Step [19/67] Loss 86853.7717\n",
      "Epoch [4/20] Step [20/67] Loss 92501.1259\n",
      "Epoch [4/20] Step [21/67] Loss 91574.4471\n",
      "Epoch [4/20] Step [22/67] Loss 40000.2929\n",
      "Epoch [4/20] Step [23/67] Loss 90872.7269\n",
      "Epoch [4/20] Step [24/67] Loss 60145.1601\n",
      "Epoch [4/20] Step [25/67] Loss 60974.7181\n",
      "Epoch [4/20] Step [26/67] Loss 29434.0158\n",
      "Epoch [4/20] Step [27/67] Loss 298639.8309\n",
      "Epoch [4/20] Step [28/67] Loss 59948.0984\n",
      "Epoch [4/20] Step [29/67] Loss 285876.4982\n",
      "Epoch [4/20] Step [30/67] Loss 199303.7910\n",
      "Epoch [4/20] Step [31/67] Loss 224453.3637\n",
      "Epoch [4/20] Step [32/67] Loss 177371.7040\n",
      "Epoch [4/20] Step [33/67] Loss 91018.5694\n",
      "Epoch [4/20] Step [34/67] Loss 174751.8736\n",
      "Epoch [4/20] Step [35/67] Loss 18963.5985\n",
      "Epoch [4/20] Step [36/67] Loss 254088.8699\n",
      "Epoch [4/20] Step [37/67] Loss 8299.6557\n",
      "Epoch [4/20] Step [38/67] Loss 130832.2701\n",
      "Epoch [4/20] Step [39/67] Loss 252798.7438\n",
      "Epoch [4/20] Step [40/67] Loss 59100.3749\n",
      "Epoch [4/20] Step [41/67] Loss 161201.0193\n",
      "Epoch [4/20] Step [42/67] Loss 117277.4043\n",
      "Epoch [4/20] Step [43/67] Loss 64816.8472\n",
      "Epoch [4/20] Step [44/67] Loss 17917.4288\n",
      "Epoch [4/20] Step [45/67] Loss 315546.9762\n",
      "Epoch [4/20] Step [46/67] Loss 29252.4773\n",
      "Epoch [4/20] Step [47/67] Loss 51306.8086\n",
      "Epoch [4/20] Step [48/67] Loss 112985.0064\n",
      "Epoch [4/20] Step [49/67] Loss 360552.1115\n",
      "Epoch [4/20] Step [50/67] Loss 29640.9337\n",
      "Epoch [4/20] Step [51/67] Loss 35674.3019\n",
      "Epoch [4/20] Step [52/67] Loss 233657.0131\n",
      "Epoch [4/20] Step [53/67] Loss 221597.4894\n",
      "Epoch [4/20] Step [54/67] Loss 263262.8176\n",
      "Epoch [4/20] Step [55/67] Loss 18177.4615\n",
      "Epoch [4/20] Step [56/67] Loss 64092.8231\n",
      "Epoch [4/20] Step [57/67] Loss 46943.1595\n",
      "Epoch [4/20] Step [58/67] Loss 143282.3934\n",
      "Epoch [4/20] Step [59/67] Loss 116784.1690\n",
      "Epoch [4/20] Step [60/67] Loss 71337.3480\n",
      "Epoch [4/20] Step [61/67] Loss 180212.2176\n",
      "Epoch [4/20] Step [62/67] Loss 163647.1827\n",
      "Epoch [4/20] Step [63/67] Loss 124453.2940\n",
      "Epoch [4/20] Step [64/67] Loss 26658.2023\n",
      "Epoch [4/20] Step [65/67] Loss 13008.6028\n",
      "Epoch [4/20] Step [66/67] Loss 47416.4908\n",
      "Epoch [5/20] Step [0/67] Loss 77837.3247\n",
      "Epoch [5/20] Step [1/67] Loss 87479.1918\n",
      "Epoch [5/20] Step [2/67] Loss 64654.6545\n",
      "Epoch [5/20] Step [3/67] Loss 46114.3947\n",
      "Epoch [5/20] Step [4/67] Loss 45815.8742\n",
      "Epoch [5/20] Step [5/67] Loss 75595.3318\n",
      "Epoch [5/20] Step [6/67] Loss 110553.0318\n",
      "Epoch [5/20] Step [7/67] Loss 128859.8462\n",
      "Epoch [5/20] Step [8/67] Loss 178777.6003\n",
      "Epoch [5/20] Step [9/67] Loss 190946.3293\n",
      "Epoch [5/20] Step [10/67] Loss 75940.2448\n",
      "Epoch [5/20] Step [11/67] Loss 52467.5618\n",
      "Epoch [5/20] Step [12/67] Loss 197003.0568\n",
      "Epoch [5/20] Step [13/67] Loss 91304.6123\n",
      "Epoch [5/20] Step [14/67] Loss 170040.9750\n",
      "Epoch [5/20] Step [15/67] Loss 20250.5423\n",
      "Epoch [5/20] Step [16/67] Loss 103407.9419\n",
      "Epoch [5/20] Step [17/67] Loss 6729.1879\n",
      "Epoch [5/20] Step [18/67] Loss 152910.3321\n",
      "Epoch [5/20] Step [19/67] Loss 59720.9915\n",
      "Epoch [5/20] Step [20/67] Loss 67154.1922\n",
      "Epoch [5/20] Step [21/67] Loss 63709.1371\n",
      "Epoch [5/20] Step [22/67] Loss 23051.7801\n",
      "Epoch [5/20] Step [23/67] Loss 79028.5534\n",
      "Epoch [5/20] Step [24/67] Loss 49179.0391\n",
      "Epoch [5/20] Step [25/67] Loss 35848.6187\n",
      "Epoch [5/20] Step [26/67] Loss 19375.2217\n",
      "Epoch [5/20] Step [27/67] Loss 236389.8093\n",
      "Epoch [5/20] Step [28/67] Loss 39096.8516\n",
      "Epoch [5/20] Step [29/67] Loss 220933.7842\n",
      "Epoch [5/20] Step [30/67] Loss 162314.5752\n",
      "Epoch [5/20] Step [31/67] Loss 166273.0680\n",
      "Epoch [5/20] Step [32/67] Loss 127081.8417\n",
      "Epoch [5/20] Step [33/67] Loss 57750.9361\n",
      "Epoch [5/20] Step [34/67] Loss 125049.9003\n",
      "Epoch [5/20] Step [35/67] Loss 9062.4280\n",
      "Epoch [5/20] Step [36/67] Loss 193238.4052\n",
      "Epoch [5/20] Step [37/67] Loss 7385.6630\n",
      "Epoch [5/20] Step [38/67] Loss 95510.4084\n",
      "Epoch [5/20] Step [39/67] Loss 191616.0710\n",
      "Epoch [5/20] Step [40/67] Loss 33609.6529\n",
      "Epoch [5/20] Step [41/67] Loss 113172.5478\n",
      "Epoch [5/20] Step [42/67] Loss 81326.7370\n",
      "Epoch [5/20] Step [43/67] Loss 37900.3503\n",
      "Epoch [5/20] Step [44/67] Loss 9021.2629\n",
      "Epoch [5/20] Step [45/67] Loss 248129.1578\n",
      "Epoch [5/20] Step [46/67] Loss 17101.5145\n",
      "Epoch [5/20] Step [47/67] Loss 32121.7745\n",
      "Epoch [5/20] Step [48/67] Loss 75487.9484\n",
      "Epoch [5/20] Step [49/67] Loss 292849.3422\n",
      "Epoch [5/20] Step [50/67] Loss 16755.4075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20] Step [51/67] Loss 26150.9438\n",
      "Epoch [5/20] Step [52/67] Loss 177869.1689\n",
      "Epoch [5/20] Step [53/67] Loss 179464.9785\n",
      "Epoch [5/20] Step [54/67] Loss 205342.4151\n",
      "Epoch [5/20] Step [55/67] Loss 7524.7610\n",
      "Epoch [5/20] Step [56/67] Loss 67899.2743\n",
      "Epoch [5/20] Step [57/67] Loss 25346.1387\n",
      "Epoch [5/20] Step [58/67] Loss 102216.4871\n",
      "Epoch [5/20] Step [59/67] Loss 83920.4913\n",
      "Epoch [5/20] Step [60/67] Loss 45372.9263\n",
      "Epoch [5/20] Step [61/67] Loss 138234.6300\n",
      "Epoch [5/20] Step [62/67] Loss 117484.4644\n",
      "Epoch [5/20] Step [63/67] Loss 84561.3366\n",
      "Epoch [5/20] Step [64/67] Loss 16085.1511\n",
      "Epoch [5/20] Step [65/67] Loss 8744.2353\n",
      "Epoch [5/20] Step [66/67] Loss 34391.9267\n",
      "Epoch [6/20] Step [0/67] Loss 59682.1611\n",
      "Epoch [6/20] Step [1/67] Loss 70902.7574\n",
      "Epoch [6/20] Step [2/67] Loss 40879.1737\n",
      "Epoch [6/20] Step [3/67] Loss 26661.0826\n",
      "Epoch [6/20] Step [4/67] Loss 27602.5128\n",
      "Epoch [6/20] Step [5/67] Loss 49377.2338\n",
      "Epoch [6/20] Step [6/67] Loss 79331.0838\n",
      "Epoch [6/20] Step [7/67] Loss 104626.2770\n",
      "Epoch [6/20] Step [8/67] Loss 133954.5981\n",
      "Epoch [6/20] Step [9/67] Loss 143667.5607\n",
      "Epoch [6/20] Step [10/67] Loss 53240.2829\n",
      "Epoch [6/20] Step [11/67] Loss 48900.7051\n",
      "Epoch [6/20] Step [12/67] Loss 159134.0637\n",
      "Epoch [6/20] Step [13/67] Loss 68563.3259\n",
      "Epoch [6/20] Step [14/67] Loss 125783.5008\n",
      "Epoch [6/20] Step [15/67] Loss 16623.8237\n",
      "Epoch [6/20] Step [16/67] Loss 71875.4310\n",
      "Epoch [6/20] Step [17/67] Loss 4706.7145\n",
      "Epoch [6/20] Step [18/67] Loss 112669.7352\n",
      "Epoch [6/20] Step [19/67] Loss 43136.1953\n",
      "Epoch [6/20] Step [20/67] Loss 51932.4589\n",
      "Epoch [6/20] Step [21/67] Loss 46551.9771\n",
      "Epoch [6/20] Step [22/67] Loss 15717.6499\n",
      "Epoch [6/20] Step [23/67] Loss 75644.9951\n",
      "Epoch [6/20] Step [24/67] Loss 47514.5070\n",
      "Epoch [6/20] Step [25/67] Loss 21458.4426\n",
      "Epoch [6/20] Step [26/67] Loss 18261.7947\n",
      "Epoch [6/20] Step [27/67] Loss 192231.1267\n",
      "Epoch [6/20] Step [28/67] Loss 28935.5084\n",
      "Epoch [6/20] Step [29/67] Loss 174863.3892\n",
      "Epoch [6/20] Step [30/67] Loss 138625.2189\n",
      "Epoch [6/20] Step [31/67] Loss 125208.3458\n",
      "Epoch [6/20] Step [32/67] Loss 92448.9188\n",
      "Epoch [6/20] Step [33/67] Loss 37812.9794\n",
      "Epoch [6/20] Step [34/67] Loss 90878.9294\n",
      "Epoch [6/20] Step [35/67] Loss 7232.2592\n",
      "Epoch [6/20] Step [36/67] Loss 150820.9069\n",
      "Epoch [6/20] Step [37/67] Loss 13596.7489\n",
      "Epoch [6/20] Step [38/67] Loss 73659.9815\n",
      "Epoch [6/20] Step [39/67] Loss 149055.7965\n",
      "Epoch [6/20] Step [40/67] Loss 19786.4960\n",
      "Epoch [6/20] Step [41/67] Loss 80977.7267\n",
      "Epoch [6/20] Step [42/67] Loss 57841.6984\n",
      "Epoch [6/20] Step [43/67] Loss 22404.4516\n",
      "Epoch [6/20] Step [44/67] Loss 8580.2368\n",
      "Epoch [6/20] Step [45/67] Loss 200172.2758\n",
      "Epoch [6/20] Step [46/67] Loss 13665.1270\n",
      "Epoch [6/20] Step [47/67] Loss 22873.8137\n",
      "Epoch [6/20] Step [48/67] Loss 51571.2174\n",
      "Epoch [6/20] Step [49/67] Loss 245975.6037\n",
      "Epoch [6/20] Step [50/67] Loss 12643.5222\n",
      "Epoch [6/20] Step [51/67] Loss 24859.6318\n",
      "Epoch [6/20] Step [52/67] Loss 139451.2651\n",
      "Epoch [6/20] Step [53/67] Loss 152977.4879\n",
      "Epoch [6/20] Step [54/67] Loss 166627.7078\n",
      "Epoch [6/20] Step [55/67] Loss 4864.6877\n",
      "Epoch [6/20] Step [56/67] Loss 76386.5283\n",
      "Epoch [6/20] Step [57/67] Loss 14773.0276\n",
      "Epoch [6/20] Step [58/67] Loss 77587.1164\n",
      "Epoch [6/20] Step [59/67] Loss 64713.6078\n",
      "Epoch [6/20] Step [60/67] Loss 32296.8365\n",
      "Epoch [6/20] Step [61/67] Loss 113146.8021\n",
      "Epoch [6/20] Step [62/67] Loss 87917.8679\n",
      "Epoch [6/20] Step [63/67] Loss 59925.4660\n",
      "Epoch [6/20] Step [64/67] Loss 13164.1067\n",
      "Epoch [6/20] Step [65/67] Loss 10457.2577\n",
      "Epoch [6/20] Step [66/67] Loss 29865.6944\n",
      "Epoch [7/20] Step [0/67] Loss 50336.8538\n",
      "Epoch [7/20] Step [1/67] Loss 64262.4624\n",
      "Epoch [7/20] Step [2/67] Loss 27919.3955\n",
      "Epoch [7/20] Step [3/67] Loss 17089.5460\n",
      "Epoch [7/20] Step [4/67] Loss 18596.2205\n",
      "Epoch [7/20] Step [5/67] Loss 34404.4574\n",
      "Epoch [7/20] Step [6/67] Loss 59985.1042\n",
      "Epoch [7/20] Step [7/67] Loss 91030.0639\n",
      "Epoch [7/20] Step [8/67] Loss 106240.4015\n",
      "Epoch [7/20] Step [9/67] Loss 114372.2980\n",
      "Epoch [7/20] Step [10/67] Loss 41047.3907\n",
      "Epoch [7/20] Step [11/67] Loss 50911.7551\n",
      "Epoch [7/20] Step [12/67] Loss 136827.6322\n",
      "Epoch [7/20] Step [13/67] Loss 58388.2647\n",
      "Epoch [7/20] Step [14/67] Loss 98588.9779\n",
      "Epoch [7/20] Step [15/67] Loss 18749.3557\n",
      "Epoch [7/20] Step [16/67] Loss 53568.4030\n",
      "Epoch [7/20] Step [17/67] Loss 7766.9007\n",
      "Epoch [7/20] Step [18/67] Loss 88342.6679\n",
      "Epoch [7/20] Step [19/67] Loss 35455.0857\n",
      "Epoch [7/20] Step [20/67] Loss 44981.9950\n",
      "Epoch [7/20] Step [21/67] Loss 38150.4523\n",
      "Epoch [7/20] Step [22/67] Loss 14747.8925\n",
      "Epoch [7/20] Step [23/67] Loss 77286.4406\n",
      "Epoch [7/20] Step [24/67] Loss 50869.1994\n",
      "Epoch [7/20] Step [25/67] Loss 15200.6620\n",
      "Epoch [7/20] Step [26/67] Loss 21916.0429\n",
      "Epoch [7/20] Step [27/67] Loss 164347.0167\n",
      "Epoch [7/20] Step [28/67] Loss 25561.8778\n",
      "Epoch [7/20] Step [29/67] Loss 145972.9696\n",
      "Epoch [7/20] Step [30/67] Loss 125827.0125\n",
      "Epoch [7/20] Step [31/67] Loss 99545.6097\n",
      "Epoch [7/20] Step [32/67] Loss 71275.4363\n",
      "Epoch [7/20] Step [33/67] Loss 27671.7878\n",
      "Epoch [7/20] Step [34/67] Loss 70037.2647\n",
      "Epoch [7/20] Step [35/67] Loss 9438.4949\n",
      "Epoch [7/20] Step [36/67] Loss 124314.8898\n",
      "Epoch [7/20] Step [37/67] Loss 22092.9544\n",
      "Epoch [7/20] Step [38/67] Loss 61621.3180\n",
      "Epoch [7/20] Step [39/67] Loss 121822.5659\n",
      "Epoch [7/20] Step [40/67] Loss 13051.4637\n",
      "Epoch [7/20] Step [41/67] Loss 61457.4124\n",
      "Epoch [7/20] Step [42/67] Loss 44328.0487\n",
      "Epoch [7/20] Step [43/67] Loss 14743.0240\n",
      "Epoch [7/20] Step [44/67] Loss 11998.5173\n",
      "Epoch [7/20] Step [45/67] Loss 168588.5336\n",
      "Epoch [7/20] Step [46/67] Loss 14855.8197\n",
      "Epoch [7/20] Step [47/67] Loss 19535.0850\n",
      "Epoch [7/20] Step [48/67] Loss 37336.2897\n",
      "Epoch [7/20] Step [49/67] Loss 215030.8449\n",
      "Epoch [7/20] Step [50/67] Loss 13164.7808\n",
      "Epoch [7/20] Step [51/67] Loss 27211.7838\n",
      "Epoch [7/20] Step [52/67] Loss 114637.5228\n",
      "Epoch [7/20] Step [53/67] Loss 136861.4664\n",
      "Epoch [7/20] Step [54/67] Loss 141642.5315\n",
      "Epoch [7/20] Step [55/67] Loss 6047.8287\n",
      "Epoch [7/20] Step [56/67] Loss 85610.8033\n",
      "Epoch [7/20] Step [57/67] Loss 9887.6519\n",
      "Epoch [7/20] Step [58/67] Loss 62749.8337\n",
      "Epoch [7/20] Step [59/67] Loss 53922.3945\n",
      "Epoch [7/20] Step [60/67] Loss 26120.7519\n",
      "Epoch [7/20] Step [61/67] Loss 98455.7399\n",
      "Epoch [7/20] Step [62/67] Loss 69745.8506\n",
      "Epoch [7/20] Step [63/67] Loss 45542.2146\n",
      "Epoch [7/20] Step [64/67] Loss 14025.1668\n",
      "Epoch [7/20] Step [65/67] Loss 14838.4195\n",
      "Epoch [7/20] Step [66/67] Loss 29209.9474\n",
      "Epoch [8/20] Step [0/67] Loss 46690.3936\n",
      "Epoch [8/20] Step [1/67] Loss 62362.2232\n",
      "Epoch [8/20] Step [2/67] Loss 21700.1187\n",
      "Epoch [8/20] Step [3/67] Loss 13188.1415\n",
      "Epoch [8/20] Step [4/67] Loss 15042.3920\n",
      "Epoch [8/20] Step [5/67] Loss 26358.0978\n",
      "Epoch [8/20] Step [6/67] Loss 49163.2372\n",
      "Epoch [8/20] Step [7/67] Loss 84335.5754\n",
      "Epoch [8/20] Step [8/67] Loss 89649.7490\n",
      "Epoch [8/20] Step [9/67] Loss 96811.3251\n",
      "Epoch [8/20] Step [10/67] Loss 34792.0124\n",
      "Epoch [8/20] Step [11/67] Loss 54757.1598\n",
      "Epoch [8/20] Step [12/67] Loss 123586.2815\n",
      "Epoch [8/20] Step [13/67] Loss 53719.0475\n",
      "Epoch [8/20] Step [14/67] Loss 82166.4174\n",
      "Epoch [8/20] Step [15/67] Loss 22875.1245\n",
      "Epoch [8/20] Step [16/67] Loss 43393.0276\n",
      "Epoch [8/20] Step [17/67] Loss 12141.7689\n",
      "Epoch [8/20] Step [18/67] Loss 74164.1242\n",
      "Epoch [8/20] Step [19/67] Loss 32695.8064\n",
      "Epoch [8/20] Step [20/67] Loss 42553.9692\n",
      "Epoch [8/20] Step [21/67] Loss 34475.3847\n",
      "Epoch [8/20] Step [22/67] Loss 16314.7498\n",
      "Epoch [8/20] Step [23/67] Loss 80589.6655\n",
      "Epoch [8/20] Step [24/67] Loss 55344.6111\n",
      "Epoch [8/20] Step [25/67] Loss 12967.5505\n",
      "Epoch [8/20] Step [26/67] Loss 26652.3709\n",
      "Epoch [8/20] Step [27/67] Loss 146675.4581\n",
      "Epoch [8/20] Step [28/67] Loss 25055.9411\n",
      "Epoch [8/20] Step [29/67] Loss 128002.1612\n",
      "Epoch [8/20] Step [30/67] Loss 119226.4247\n",
      "Epoch [8/20] Step [31/67] Loss 83785.0176\n",
      "Epoch [8/20] Step [32/67] Loss 58579.7939\n",
      "Epoch [8/20] Step [33/67] Loss 22756.6462\n",
      "Epoch [8/20] Step [34/67] Loss 57571.4007\n",
      "Epoch [8/20] Step [35/67] Loss 12714.0967\n",
      "Epoch [8/20] Step [36/67] Loss 108086.2367\n",
      "Epoch [8/20] Step [37/67] Loss 29893.2956\n",
      "Epoch [8/20] Step [38/67] Loss 55080.5010\n",
      "Epoch [8/20] Step [39/67] Loss 104711.4032\n",
      "Epoch [8/20] Step [40/67] Loss 9969.5000\n",
      "Epoch [8/20] Step [41/67] Loss 49842.4580\n",
      "Epoch [8/20] Step [42/67] Loss 36787.4153\n",
      "Epoch [8/20] Step [43/67] Loss 11208.1561\n",
      "Epoch [8/20] Step [44/67] Loss 16169.1003\n",
      "Epoch [8/20] Step [45/67] Loss 148377.8079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20] Step [46/67] Loss 17492.2617\n",
      "Epoch [8/20] Step [47/67] Loss 18893.3620\n",
      "Epoch [8/20] Step [48/67] Loss 29058.0684\n",
      "Epoch [8/20] Step [49/67] Loss 195153.8573\n",
      "Epoch [8/20] Step [50/67] Loss 15219.6267\n",
      "Epoch [8/20] Step [51/67] Loss 30462.3084\n",
      "Epoch [8/20] Step [52/67] Loss 98964.0071\n",
      "Epoch [8/20] Step [53/67] Loss 127133.8760\n",
      "Epoch [8/20] Step [54/67] Loss 125674.0062\n",
      "Epoch [8/20] Step [55/67] Loss 8427.6209\n",
      "Epoch [8/20] Step [56/67] Loss 93636.5080\n",
      "Epoch [8/20] Step [57/67] Loss 7842.2990\n",
      "Epoch [8/20] Step [58/67] Loss 53701.7545\n",
      "Epoch [8/20] Step [59/67] Loss 47790.3253\n",
      "Epoch [8/20] Step [60/67] Loss 23251.9911\n",
      "Epoch [8/20] Step [61/67] Loss 89556.9346\n",
      "Epoch [8/20] Step [62/67] Loss 58302.8720\n",
      "Epoch [8/20] Step [63/67] Loss 36859.4297\n",
      "Epoch [8/20] Step [64/67] Loss 16118.3861\n",
      "Epoch [8/20] Step [65/67] Loss 19509.1752\n",
      "Epoch [8/20] Step [66/67] Loss 30080.2274\n",
      "Epoch [9/20] Step [0/67] Loss 45548.6555\n",
      "Epoch [9/20] Step [1/67] Loss 62415.4302\n",
      "Epoch [9/20] Step [2/67] Loss 18630.8397\n",
      "Epoch [9/20] Step [3/67] Loss 11717.7775\n",
      "Epoch [9/20] Step [4/67] Loss 13830.8057\n",
      "Epoch [9/20] Step [5/67] Loss 21801.3377\n",
      "Epoch [9/20] Step [6/67] Loss 42590.9087\n",
      "Epoch [9/20] Step [7/67] Loss 80770.0652\n",
      "Epoch [9/20] Step [8/67] Loss 78957.4819\n",
      "Epoch [9/20] Step [9/67] Loss 85438.5919\n",
      "Epoch [9/20] Step [10/67] Loss 31426.3185\n",
      "Epoch [9/20] Step [11/67] Loss 58729.1189\n",
      "Epoch [9/20] Step [12/67] Loss 115232.2320\n",
      "Epoch [9/20] Step [13/67] Loss 51675.8832\n",
      "Epoch [9/20] Step [14/67] Loss 71538.0184\n",
      "Epoch [9/20] Step [15/67] Loss 27033.9658\n",
      "Epoch [9/20] Step [16/67] Loss 37178.0828\n",
      "Epoch [9/20] Step [17/67] Loss 16423.6824\n",
      "Epoch [9/20] Step [18/67] Loss 65143.2496\n",
      "Epoch [9/20] Step [19/67] Loss 31819.0121\n",
      "Epoch [9/20] Step [20/67] Loss 41881.2949\n",
      "Epoch [9/20] Step [21/67] Loss 32877.0502\n",
      "Epoch [9/20] Step [22/67] Loss 18535.7148\n",
      "Epoch [9/20] Step [23/67] Loss 83991.9469\n",
      "Epoch [9/20] Step [24/67] Loss 59640.6653\n",
      "Epoch [9/20] Step [25/67] Loss 12373.1420\n",
      "Epoch [9/20] Step [26/67] Loss 31108.6697\n",
      "Epoch [9/20] Step [27/67] Loss 135114.8699\n",
      "Epoch [9/20] Step [28/67] Loss 25702.0569\n",
      "Epoch [9/20] Step [29/67] Loss 116241.3307\n",
      "Epoch [9/20] Step [30/67] Loss 115556.8784\n",
      "Epoch [9/20] Step [31/67] Loss 73508.2879\n",
      "Epoch [9/20] Step [32/67] Loss 50496.2666\n",
      "Epoch [9/20] Step [33/67] Loss 20293.2366\n",
      "Epoch [9/20] Step [34/67] Loss 49579.5383\n",
      "Epoch [9/20] Step [35/67] Loss 15926.4698\n",
      "Epoch [9/20] Step [36/67] Loss 97573.9891\n",
      "Epoch [9/20] Step [37/67] Loss 36393.3508\n",
      "Epoch [9/20] Step [38/67] Loss 51325.5371\n",
      "Epoch [9/20] Step [39/67] Loss 93485.4504\n",
      "Epoch [9/20] Step [40/67] Loss 8729.3995\n",
      "Epoch [9/20] Step [41/67] Loss 42484.3450\n",
      "Epoch [9/20] Step [42/67] Loss 32216.1768\n",
      "Epoch [9/20] Step [43/67] Loss 9532.9968\n",
      "Epoch [9/20] Step [44/67] Loss 20034.2059\n",
      "Epoch [9/20] Step [45/67] Loss 134937.0740\n",
      "Epoch [9/20] Step [46/67] Loss 20207.7034\n",
      "Epoch [9/20] Step [47/67] Loss 19268.9309\n",
      "Epoch [9/20] Step [48/67] Loss 24035.0210\n",
      "Epoch [9/20] Step [49/67] Loss 182057.6412\n",
      "Epoch [9/20] Step [50/67] Loss 17473.5470\n",
      "Epoch [9/20] Step [51/67] Loss 33605.0914\n",
      "Epoch [9/20] Step [52/67] Loss 88678.9330\n",
      "Epoch [9/20] Step [53/67] Loss 121121.9944\n",
      "Epoch [9/20] Step [54/67] Loss 115240.0062\n",
      "Epoch [9/20] Step [55/67] Loss 10878.4193\n",
      "Epoch [9/20] Step [56/67] Loss 100076.9983\n",
      "Epoch [9/20] Step [57/67] Loss 7234.6819\n",
      "Epoch [9/20] Step [58/67] Loss 48186.1233\n",
      "Epoch [9/20] Step [59/67] Loss 44243.7337\n",
      "Epoch [9/20] Step [60/67] Loss 22015.6586\n",
      "Epoch [9/20] Step [61/67] Loss 84055.6928\n",
      "Epoch [9/20] Step [62/67] Loss 50935.1614\n",
      "Epoch [9/20] Step [63/67] Loss 31418.4647\n",
      "Epoch [9/20] Step [64/67] Loss 18294.8915\n",
      "Epoch [9/20] Step [65/67] Loss 23454.8822\n",
      "Epoch [9/20] Step [66/67] Loss 31441.5466\n",
      "Epoch [10/20] Step [0/67] Loss 45353.8795\n",
      "Epoch [10/20] Step [1/67] Loss 63188.1987\n",
      "Epoch [10/20] Step [2/67] Loss 17074.9886\n",
      "Epoch [10/20] Step [3/67] Loss 11291.9391\n",
      "Epoch [10/20] Step [4/67] Loss 13589.9804\n",
      "Epoch [10/20] Step [5/67] Loss 19212.2095\n",
      "Epoch [10/20] Step [6/67] Loss 38473.0354\n",
      "Epoch [10/20] Step [7/67] Loss 78800.3299\n",
      "Epoch [10/20] Step [8/67] Loss 72000.4120\n",
      "Epoch [10/20] Step [9/67] Loss 77998.6471\n",
      "Epoch [10/20] Step [10/67] Loss 29665.4374\n",
      "Epoch [10/20] Step [11/67] Loss 62137.6200\n",
      "Epoch [10/20] Step [12/67] Loss 109985.5094\n",
      "Epoch [10/20] Step [13/67] Loss 50946.4120\n",
      "Epoch [10/20] Step [14/67] Loss 64642.7582\n",
      "Epoch [10/20] Step [15/67] Loss 30516.1098\n",
      "Epoch [10/20] Step [16/67] Loss 33332.9231\n",
      "Epoch [10/20] Step [17/67] Loss 20024.7223\n",
      "Epoch [10/20] Step [18/67] Loss 59322.4922\n",
      "Epoch [10/20] Step [19/67] Loss 31706.9769\n",
      "Epoch [10/20] Step [20/67] Loss 41916.0882\n",
      "Epoch [10/20] Step [21/67] Loss 32281.2283\n",
      "Epoch [10/20] Step [22/67] Loss 20643.2022\n",
      "Epoch [10/20] Step [23/67] Loss 86903.1332\n",
      "Epoch [10/20] Step [24/67] Loss 63202.1396\n",
      "Epoch [10/20] Step [25/67] Loss 12472.6697\n",
      "Epoch [10/20] Step [26/67] Loss 34760.0535\n",
      "Epoch [10/20] Step [27/67] Loss 127568.5809\n",
      "Epoch [10/20] Step [28/67] Loss 26681.5678\n",
      "Epoch [10/20] Step [29/67] Loss 108473.0703\n",
      "Epoch [10/20] Step [30/67] Loss 113450.3685\n",
      "Epoch [10/20] Step [31/67] Loss 66753.7088\n",
      "Epoch [10/20] Step [32/67] Loss 45286.0848\n",
      "Epoch [10/20] Step [33/67] Loss 19024.7598\n",
      "Epoch [10/20] Step [34/67] Loss 44412.5193\n",
      "Epoch [10/20] Step [35/67] Loss 18658.2224\n",
      "Epoch [10/20] Step [36/67] Loss 90608.9096\n",
      "Epoch [10/20] Step [37/67] Loss 41403.3150\n",
      "Epoch [10/20] Step [38/67] Loss 49124.9120\n",
      "Epoch [10/20] Step [39/67] Loss 86044.3284\n",
      "Epoch [10/20] Step [40/67] Loss 8313.6095\n",
      "Epoch [10/20] Step [41/67] Loss 37735.1442\n",
      "Epoch [10/20] Step [42/67] Loss 29446.2240\n",
      "Epoch [10/20] Step [43/67] Loss 8787.3700\n",
      "Epoch [10/20] Step [44/67] Loss 23160.2491\n",
      "Epoch [10/20] Step [45/67] Loss 125953.3304\n",
      "Epoch [10/20] Step [46/67] Loss 22520.7922\n",
      "Epoch [10/20] Step [47/67] Loss 19958.9293\n",
      "Epoch [10/20] Step [48/67] Loss 20936.3228\n",
      "Epoch [10/20] Step [49/67] Loss 173280.1117\n",
      "Epoch [10/20] Step [50/67] Loss 19459.8723\n",
      "Epoch [10/20] Step [51/67] Loss 36212.9814\n",
      "Epoch [10/20] Step [52/67] Loss 81850.0728\n",
      "Epoch [10/20] Step [53/67] Loss 117285.4457\n",
      "Epoch [10/20] Step [54/67] Loss 108279.8409\n",
      "Epoch [10/20] Step [55/67] Loss 13003.9537\n",
      "Epoch [10/20] Step [56/67] Loss 105016.3900\n",
      "Epoch [10/20] Step [57/67] Loss 7200.5705\n",
      "Epoch [10/20] Step [58/67] Loss 44660.1285\n",
      "Epoch [10/20] Step [59/67] Loss 42110.2216\n",
      "Epoch [10/20] Step [60/67] Loss 21493.1267\n",
      "Epoch [10/20] Step [61/67] Loss 80518.3702\n",
      "Epoch [10/20] Step [62/67] Loss 46086.9792\n",
      "Epoch [10/20] Step [63/67] Loss 27912.3821\n",
      "Epoch [10/20] Step [64/67] Loss 20195.5053\n",
      "Epoch [10/20] Step [65/67] Loss 26588.8292\n",
      "Epoch [10/20] Step [66/67] Loss 32777.9585\n",
      "Epoch [11/20] Step [0/67] Loss 45556.4896\n",
      "Epoch [11/20] Step [1/67] Loss 64086.6117\n",
      "Epoch [11/20] Step [2/67] Loss 16303.2965\n",
      "Epoch [11/20] Step [3/67] Loss 11320.2632\n",
      "Epoch [11/20] Step [4/67] Loss 13751.7902\n",
      "Epoch [11/20] Step [5/67] Loss 17717.9827\n",
      "Epoch [11/20] Step [6/67] Loss 35884.3761\n",
      "Epoch [11/20] Step [7/67] Loss 77719.8480\n",
      "Epoch [11/20] Step [8/67] Loss 67371.9959\n",
      "Epoch [11/20] Step [9/67] Loss 73024.9767\n",
      "Epoch [11/20] Step [10/67] Loss 28740.7639\n",
      "Epoch [11/20] Step [11/67] Loss 64862.6327\n",
      "Epoch [11/20] Step [12/67] Loss 106566.4737\n",
      "Epoch [11/20] Step [13/67] Loss 50698.9580\n",
      "Epoch [11/20] Step [14/67] Loss 60048.7029\n",
      "Epoch [11/20] Step [15/67] Loss 33266.4274\n",
      "Epoch [11/20] Step [16/67] Loss 30903.2966\n",
      "Epoch [11/20] Step [17/67] Loss 22862.0138\n",
      "Epoch [11/20] Step [18/67] Loss 55477.4724\n",
      "Epoch [11/20] Step [19/67] Loss 31912.6984\n",
      "Epoch [11/20] Step [20/67] Loss 42229.1557\n",
      "Epoch [11/20] Step [21/67] Loss 32146.7420\n",
      "Epoch [11/20] Step [22/67] Loss 22408.1880\n",
      "Epoch [11/20] Step [23/67] Loss 89243.7962\n",
      "Epoch [11/20] Step [24/67] Loss 65972.3962\n",
      "Epoch [11/20] Step [25/67] Loss 12814.9663\n",
      "Epoch [11/20] Step [26/67] Loss 37593.4095\n",
      "Epoch [11/20] Step [27/67] Loss 122443.7244\n",
      "Epoch [11/20] Step [28/67] Loss 27619.4580\n",
      "Epoch [11/20] Step [29/67] Loss 103163.6547\n",
      "Epoch [11/20] Step [30/67] Loss 112184.5998\n",
      "Epoch [11/20] Step [31/67] Loss 62188.5166\n",
      "Epoch [11/20] Step [32/67] Loss 41815.6412\n",
      "Epoch [11/20] Step [33/67] Loss 18326.2056\n",
      "Epoch [11/20] Step [34/67] Loss 40980.6757\n",
      "Epoch [11/20] Step [35/67] Loss 20851.5489\n",
      "Epoch [11/20] Step [36/67] Loss 85834.1366\n",
      "Epoch [11/20] Step [37/67] Loss 45173.6712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20] Step [38/67] Loss 47771.9672\n",
      "Epoch [11/20] Step [39/67] Loss 80948.0999\n",
      "Epoch [11/20] Step [40/67] Loss 8215.5587\n",
      "Epoch [11/20] Step [41/67] Loss 34563.2116\n",
      "Epoch [11/20] Step [42/67] Loss 27732.2720\n",
      "Epoch [11/20] Step [43/67] Loss 8483.2644\n",
      "Epoch [11/20] Step [44/67] Loss 25573.5369\n",
      "Epoch [11/20] Step [45/67] Loss 119781.4693\n",
      "Epoch [11/20] Step [46/67] Loss 24369.6482\n",
      "Epoch [11/20] Step [47/67] Loss 20663.9279\n",
      "Epoch [11/20] Step [48/67] Loss 18947.9500\n",
      "Epoch [11/20] Step [49/67] Loss 167211.4331\n",
      "Epoch [11/20] Step [50/67] Loss 21072.7154\n",
      "Epoch [11/20] Step [51/67] Loss 38245.9680\n",
      "Epoch [11/20] Step [52/67] Loss 77221.8029\n",
      "Epoch [11/20] Step [53/67] Loss 114736.8170\n",
      "Epoch [11/20] Step [54/67] Loss 103515.9412\n",
      "Epoch [11/20] Step [55/67] Loss 14715.8979\n",
      "Epoch [11/20] Step [56/67] Loss 108720.0395\n",
      "Epoch [11/20] Step [57/67] Loss 7351.3140\n",
      "Epoch [11/20] Step [58/67] Loss 42297.3293\n",
      "Epoch [11/20] Step [59/67] Loss 40770.2601\n",
      "Epoch [11/20] Step [60/67] Loss 21268.2590\n",
      "Epoch [11/20] Step [61/67] Loss 78157.0280\n",
      "Epoch [11/20] Step [62/67] Loss 42836.1385\n",
      "Epoch [11/20] Step [63/67] Loss 25602.8880\n",
      "Epoch [11/20] Step [64/67] Loss 21731.8658\n",
      "Epoch [11/20] Step [65/67] Loss 28998.9376\n",
      "Epoch [11/20] Step [66/67] Loss 33906.9903\n",
      "Epoch [12/20] Step [0/67] Loss 45900.4688\n",
      "Epoch [12/20] Step [1/67] Loss 64885.0400\n",
      "Epoch [12/20] Step [2/67] Loss 15939.9908\n",
      "Epoch [12/20] Step [3/67] Loss 11520.7259\n",
      "Epoch [12/20] Step [4/67] Loss 14050.1983\n",
      "Epoch [12/20] Step [5/67] Loss 16842.8209\n",
      "Epoch [12/20] Step [6/67] Loss 34256.5414\n",
      "Epoch [12/20] Step [7/67] Loss 77138.2655\n",
      "Epoch [12/20] Step [8/67] Loss 64240.2777\n",
      "Epoch [12/20] Step [9/67] Loss 69643.6803\n",
      "Epoch [12/20] Step [10/67] Loss 28253.2471\n",
      "Epoch [12/20] Step [11/67] Loss 66953.7980\n",
      "Epoch [12/20] Step [12/67] Loss 104269.7875\n",
      "Epoch [12/20] Step [13/67] Loss 50601.4841\n",
      "Epoch [12/20] Step [14/67] Loss 56925.7818\n",
      "Epoch [12/20] Step [15/67] Loss 35363.6697\n",
      "Epoch [12/20] Step [16/67] Loss 29338.2103\n",
      "Epoch [12/20] Step [17/67] Loss 25014.7990\n",
      "Epoch [12/20] Step [18/67] Loss 52890.0311\n",
      "Epoch [12/20] Step [19/67] Loss 32218.5821\n",
      "Epoch [12/20] Step [20/67] Loss 42614.8937\n",
      "Epoch [12/20] Step [21/67] Loss 32207.4207\n",
      "Epoch [12/20] Step [22/67] Loss 23796.8133\n",
      "Epoch [12/20] Step [23/67] Loss 91056.5081\n",
      "Epoch [12/20] Step [24/67] Loss 68050.9144\n",
      "Epoch [12/20] Step [25/67] Loss 13199.2426\n",
      "Epoch [12/20] Step [26/67] Loss 39721.3505\n",
      "Epoch [12/20] Step [27/67] Loss 118879.2771\n",
      "Epoch [12/20] Step [28/67] Loss 28397.3596\n",
      "Epoch [12/20] Step [29/67] Loss 99467.6294\n",
      "Epoch [12/20] Step [30/67] Loss 111396.5481\n",
      "Epoch [12/20] Step [31/67] Loss 59056.5110\n",
      "Epoch [12/20] Step [32/67] Loss 39461.4013\n",
      "Epoch [12/20] Step [33/67] Loss 17918.4975\n",
      "Epoch [12/20] Step [34/67] Loss 38666.6250\n",
      "Epoch [12/20] Step [35/67] Loss 22543.9690\n",
      "Epoch [12/20] Step [36/67] Loss 82515.9658\n",
      "Epoch [12/20] Step [37/67] Loss 47955.4615\n",
      "Epoch [12/20] Step [38/67] Loss 46913.4839\n",
      "Epoch [12/20] Step [39/67] Loss 77410.5500\n",
      "Epoch [12/20] Step [40/67] Loss 8235.3929\n",
      "Epoch [12/20] Step [41/67] Loss 32409.9525\n",
      "Epoch [12/20] Step [42/67] Loss 26655.3273\n",
      "Epoch [12/20] Step [43/67] Loss 8384.7647\n",
      "Epoch [12/20] Step [44/67] Loss 27380.5112\n",
      "Epoch [12/20] Step [45/67] Loss 115497.7630\n",
      "Epoch [12/20] Step [46/67] Loss 25787.7067\n",
      "Epoch [12/20] Step [47/67] Loss 21273.0162\n",
      "Epoch [12/20] Step [48/67] Loss 17642.5899\n",
      "Epoch [12/20] Step [49/67] Loss 162966.0474\n",
      "Epoch [12/20] Step [50/67] Loss 22319.6524\n",
      "Epoch [12/20] Step [51/67] Loss 39774.4549\n",
      "Epoch [12/20] Step [52/67] Loss 74051.6833\n",
      "Epoch [12/20] Step [53/67] Loss 113004.9570\n",
      "Epoch [12/20] Step [54/67] Loss 100213.6969\n",
      "Epoch [12/20] Step [55/67] Loss 16034.8902\n",
      "Epoch [12/20] Step [56/67] Loss 111448.1650\n",
      "Epoch [12/20] Step [57/67] Loss 7537.1413\n",
      "Epoch [12/20] Step [58/67] Loss 40670.4879\n",
      "Epoch [12/20] Step [59/67] Loss 39900.3185\n",
      "Epoch [12/20] Step [60/67] Loss 21166.4534\n",
      "Epoch [12/20] Step [61/67] Loss 76539.8423\n",
      "Epoch [12/20] Step [62/67] Loss 40627.0087\n",
      "Epoch [12/20] Step [63/67] Loss 24054.9894\n",
      "Epoch [12/20] Step [64/67] Loss 22918.3462\n",
      "Epoch [12/20] Step [65/67] Loss 30807.8257\n",
      "Epoch [12/20] Step [66/67] Loss 34796.3525\n",
      "Epoch [13/20] Step [0/67] Loss 46257.9909\n",
      "Epoch [13/20] Step [1/67] Loss 65523.0968\n",
      "Epoch [13/20] Step [2/67] Loss 15781.9310\n",
      "Epoch [13/20] Step [3/67] Loss 11759.5588\n",
      "Epoch [13/20] Step [4/67] Loss 14360.8814\n",
      "Epoch [13/20] Step [5/67] Loss 16321.9838\n",
      "Epoch [13/20] Step [6/67] Loss 33227.5111\n",
      "Epoch [13/20] Step [7/67] Loss 76830.7917\n",
      "Epoch [13/20] Step [8/67] Loss 62093.7401\n",
      "Epoch [13/20] Step [9/67] Loss 67314.3722\n",
      "Epoch [13/20] Step [10/67] Loss 27996.1772\n",
      "Epoch [13/20] Step [11/67] Loss 68517.2755\n",
      "Epoch [13/20] Step [12/67] Loss 102694.5974\n",
      "Epoch [13/20] Step [13/67] Loss 50541.4287\n",
      "Epoch [13/20] Step [14/67] Loss 54772.4422\n",
      "Epoch [13/20] Step [15/67] Loss 36925.3443\n",
      "Epoch [13/20] Step [16/67] Loss 28311.7756\n",
      "Epoch [13/20] Step [17/67] Loss 26611.1903\n",
      "Epoch [13/20] Step [18/67] Loss 51121.8985\n",
      "Epoch [13/20] Step [19/67] Loss 32522.7297\n",
      "Epoch [13/20] Step [20/67] Loss 42979.7060\n",
      "Epoch [13/20] Step [21/67] Loss 32335.3101\n",
      "Epoch [13/20] Step [22/67] Loss 24850.5792\n",
      "Epoch [13/20] Step [23/67] Loss 92425.9299\n",
      "Epoch [13/20] Step [24/67] Loss 69577.1143\n",
      "Epoch [13/20] Step [25/67] Loss 13545.6863\n",
      "Epoch [13/20] Step [26/67] Loss 41286.9041\n",
      "Epoch [13/20] Step [27/67] Loss 116367.2178\n",
      "Epoch [13/20] Step [28/67] Loss 29001.3884\n",
      "Epoch [13/20] Step [29/67] Loss 96866.2779\n",
      "Epoch [13/20] Step [30/67] Loss 110889.0402\n",
      "Epoch [13/20] Step [31/67] Loss 56886.5621\n",
      "Epoch [13/20] Step [32/67] Loss 37844.4144\n",
      "Epoch [13/20] Step [33/67] Loss 17664.9719\n",
      "Epoch [13/20] Step [34/67] Loss 37089.8851\n",
      "Epoch [13/20] Step [35/67] Loss 23816.6848\n",
      "Epoch [13/20] Step [36/67] Loss 80190.1117\n",
      "Epoch [13/20] Step [37/67] Loss 49977.8095\n",
      "Epoch [13/20] Step [38/67] Loss 46354.0900\n",
      "Epoch [13/20] Step [39/67] Loss 74937.1604\n",
      "Epoch [13/20] Step [40/67] Loss 8289.8781\n",
      "Epoch [13/20] Step [41/67] Loss 30932.1554\n",
      "Epoch [13/20] Step [42/67] Loss 25970.2024\n",
      "Epoch [13/20] Step [43/67] Loss 8376.8107\n",
      "Epoch [13/20] Step [44/67] Loss 28705.5457\n",
      "Epoch [13/20] Step [45/67] Loss 112508.0443\n",
      "Epoch [13/20] Step [46/67] Loss 26846.6962\n",
      "Epoch [13/20] Step [47/67] Loss 21760.5651\n",
      "Epoch [13/20] Step [48/67] Loss 16771.0329\n",
      "Epoch [13/20] Step [49/67] Loss 159975.5387\n",
      "Epoch [13/20] Step [50/67] Loss 23255.9876\n",
      "Epoch [13/20] Step [51/67] Loss 40898.9730\n",
      "Epoch [13/20] Step [52/67] Loss 71862.5187\n",
      "Epoch [13/20] Step [53/67] Loss 111808.7397\n",
      "Epoch [13/20] Step [54/67] Loss 97903.8644\n",
      "Epoch [13/20] Step [55/67] Loss 17025.1375\n",
      "Epoch [13/20] Step [56/67] Loss 113436.1014\n",
      "Epoch [13/20] Step [57/67] Loss 7704.4119\n",
      "Epoch [13/20] Step [58/67] Loss 39528.6319\n",
      "Epoch [13/20] Step [59/67] Loss 39319.2191\n",
      "Epoch [13/20] Step [60/67] Loss 21113.9268\n",
      "Epoch [13/20] Step [61/67] Loss 75410.3781\n",
      "Epoch [13/20] Step [62/67] Loss 39107.8818\n",
      "Epoch [13/20] Step [63/67] Loss 23000.8640\n",
      "Epoch [13/20] Step [64/67] Loss 23810.6828\n",
      "Epoch [13/20] Step [65/67] Loss 32144.8273\n",
      "Epoch [13/20] Step [66/67] Loss 35471.8097\n",
      "Epoch [14/20] Step [0/67] Loss 46575.5778\n",
      "Epoch [14/20] Step [1/67] Loss 66006.8943\n",
      "Epoch [14/20] Step [2/67] Loss 15723.0161\n",
      "Epoch [14/20] Step [3/67] Loss 11980.9462\n",
      "Epoch [14/20] Step [4/67] Loss 14634.6819\n",
      "Epoch [14/20] Step [5/67] Loss 16006.3703\n",
      "Epoch [14/20] Step [6/67] Loss 32571.0334\n",
      "Epoch [14/20] Step [7/67] Loss 76671.6246\n",
      "Epoch [14/20] Step [8/67] Loss 60605.2182\n",
      "Epoch [14/20] Step [9/67] Loss 65690.7928\n",
      "Epoch [14/20] Step [10/67] Loss 27861.0844\n",
      "Epoch [14/20] Step [11/67] Loss 69668.8861\n",
      "Epoch [14/20] Step [12/67] Loss 101596.8914\n",
      "Epoch [14/20] Step [13/67] Loss 50486.2655\n",
      "Epoch [14/20] Step [14/67] Loss 53269.8244\n",
      "Epoch [14/20] Step [15/67] Loss 38072.2054\n",
      "Epoch [14/20] Step [16/67] Loss 27626.9532\n",
      "Epoch [14/20] Step [17/67] Loss 27780.1936\n",
      "Epoch [14/20] Step [18/67] Loss 49896.9844\n",
      "Epoch [14/20] Step [19/67] Loss 32786.1466\n",
      "Epoch [14/20] Step [20/67] Loss 43289.7894\n",
      "Epoch [14/20] Step [21/67] Loss 32472.8612\n",
      "Epoch [14/20] Step [22/67] Loss 25634.1451\n",
      "Epoch [14/20] Step [23/67] Loss 93445.3138\n",
      "Epoch [14/20] Step [24/67] Loss 70684.8470\n",
      "Epoch [14/20] Step [25/67] Loss 13830.9991\n",
      "Epoch [14/20] Step [26/67] Loss 42425.7708\n",
      "Epoch [14/20] Step [27/67] Loss 114579.9253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20] Step [28/67] Loss 29454.7582\n",
      "Epoch [14/20] Step [29/67] Loss 95019.0179\n",
      "Epoch [14/20] Step [30/67] Loss 110551.5977\n",
      "Epoch [14/20] Step [31/67] Loss 55369.5694\n",
      "Epoch [14/20] Step [32/67] Loss 36721.3518\n",
      "Epoch [14/20] Step [33/67] Loss 17497.1263\n",
      "Epoch [14/20] Step [34/67] Loss 36004.6631\n",
      "Epoch [14/20] Step [35/67] Loss 24759.8479\n",
      "Epoch [14/20] Step [36/67] Loss 78546.1928\n",
      "Epoch [14/20] Step [37/67] Loss 51436.4856\n",
      "Epoch [14/20] Step [38/67] Loss 45980.5382\n",
      "Epoch [14/20] Step [39/67] Loss 73195.8533\n",
      "Epoch [14/20] Step [40/67] Loss 8346.2779\n",
      "Epoch [14/20] Step [41/67] Loss 29907.2051\n",
      "Epoch [14/20] Step [42/67] Loss 25528.5200\n",
      "Epoch [14/20] Step [43/67] Loss 8404.2293\n",
      "Epoch [14/20] Step [44/67] Loss 29666.0372\n",
      "Epoch [14/20] Step [45/67] Loss 110408.8945\n",
      "Epoch [14/20] Step [46/67] Loss 27625.6861\n",
      "Epoch [14/20] Step [47/67] Loss 22135.7139\n",
      "Epoch [14/20] Step [48/67] Loss 16180.1587\n",
      "Epoch [14/20] Step [49/67] Loss 157855.4889\n",
      "Epoch [14/20] Step [50/67] Loss 23947.8223\n",
      "Epoch [14/20] Step [51/67] Loss 41716.9722\n",
      "Epoch [14/20] Step [52/67] Loss 70338.1854\n",
      "Epoch [14/20] Step [53/67] Loss 110971.5733\n",
      "Epoch [14/20] Step [54/67] Loss 96275.1164\n",
      "Epoch [14/20] Step [55/67] Loss 17757.9886\n",
      "Epoch [14/20] Step [56/67] Loss 114877.2939\n",
      "Epoch [14/20] Step [57/67] Loss 7839.3284\n",
      "Epoch [14/20] Step [58/67] Loss 38716.2090\n",
      "Epoch [14/20] Step [59/67] Loss 38921.9028\n",
      "Epoch [14/20] Step [60/67] Loss 21081.4469\n",
      "Epoch [14/20] Step [61/67] Loss 74610.0484\n",
      "Epoch [14/20] Step [62/67] Loss 38051.6413\n",
      "Epoch [14/20] Step [63/67] Loss 22272.4674\n",
      "Epoch [14/20] Step [64/67] Loss 24471.8982\n",
      "Epoch [14/20] Step [65/67] Loss 33124.4126\n",
      "Epoch [14/20] Step [66/67] Loss 35975.0012\n",
      "Epoch [15/20] Step [0/67] Loss 46837.0494\n",
      "Epoch [15/20] Step [1/67] Loss 66364.1610\n",
      "Epoch [15/20] Step [2/67] Loss 15709.3932\n",
      "Epoch [15/20] Step [3/67] Loss 12166.2405\n",
      "Epoch [15/20] Step [4/67] Loss 14858.1460\n",
      "Epoch [15/20] Step [5/67] Loss 15811.2663\n",
      "Epoch [15/20] Step [6/67] Loss 32146.6533\n",
      "Epoch [15/20] Step [7/67] Loss 76591.2690\n",
      "Epoch [15/20] Step [8/67] Loss 59562.1884\n",
      "Epoch [15/20] Step [9/67] Loss 64547.6055\n",
      "Epoch [15/20] Step [10/67] Loss 27790.6843\n",
      "Epoch [15/20] Step [11/67] Loss 70510.5427\n",
      "Epoch [15/20] Step [12/67] Loss 100822.7768\n",
      "Epoch [15/20] Step [13/67] Loss 50431.8226\n",
      "Epoch [15/20] Step [14/67] Loss 52210.8330\n",
      "Epoch [15/20] Step [15/67] Loss 38908.3224\n",
      "Epoch [15/20] Step [16/67] Loss 27162.5278\n",
      "Epoch [15/20] Step [17/67] Loss 28631.0658\n",
      "Epoch [15/20] Step [18/67] Loss 49038.3038\n",
      "Epoch [15/20] Step [19/67] Loss 32999.4817\n",
      "Epoch [15/20] Step [20/67] Loss 43539.1485\n",
      "Epoch [15/20] Step [21/67] Loss 32596.7860\n",
      "Epoch [15/20] Step [22/67] Loss 26210.5277\n",
      "Epoch [15/20] Step [23/67] Loss 94197.7939\n",
      "Epoch [15/20] Step [24/67] Loss 71484.8587\n",
      "Epoch [15/20] Step [25/67] Loss 14055.3818\n",
      "Epoch [15/20] Step [26/67] Loss 43250.0359\n",
      "Epoch [15/20] Step [27/67] Loss 113299.2772\n",
      "Epoch [15/20] Step [28/67] Loss 29789.2110\n",
      "Epoch [15/20] Step [29/67] Loss 93697.7292\n",
      "Epoch [15/20] Step [30/67] Loss 110321.1131\n",
      "Epoch [15/20] Step [31/67] Loss 54300.1034\n",
      "Epoch [15/20] Step [32/67] Loss 35933.4665\n",
      "Epoch [15/20] Step [33/67] Loss 17380.4093\n",
      "Epoch [15/20] Step [34/67] Loss 35250.2076\n",
      "Epoch [15/20] Step [35/67] Loss 25453.3785\n",
      "Epoch [15/20] Step [36/67] Loss 77375.5411\n",
      "Epoch [15/20] Step [37/67] Loss 52485.5586\n",
      "Epoch [15/20] Step [38/67] Loss 45725.8183\n",
      "Epoch [15/20] Step [39/67] Loss 71961.6198\n",
      "Epoch [15/20] Step [40/67] Loss 8394.1004\n",
      "Epoch [15/20] Step [41/67] Loss 29189.1554\n",
      "Epoch [15/20] Step [42/67] Loss 25239.5265\n",
      "Epoch [15/20] Step [43/67] Loss 8441.5406\n",
      "Epoch [15/20] Step [44/67] Loss 30358.7937\n",
      "Epoch [15/20] Step [45/67] Loss 108925.6683\n",
      "Epoch [15/20] Step [46/67] Loss 28194.2489\n",
      "Epoch [15/20] Step [47/67] Loss 22418.1755\n",
      "Epoch [15/20] Step [48/67] Loss 15774.0531\n",
      "Epoch [15/20] Step [49/67] Loss 156343.9131\n",
      "Epoch [15/20] Step [50/67] Loss 24454.6313\n",
      "Epoch [15/20] Step [51/67] Loss 42309.0317\n",
      "Epoch [15/20] Step [52/67] Loss 69268.3098\n",
      "Epoch [15/20] Step [53/67] Loss 110379.7055\n",
      "Epoch [15/20] Step [54/67] Loss 95118.6830\n",
      "Epoch [15/20] Step [55/67] Loss 18296.1003\n",
      "Epoch [15/20] Step [56/67] Loss 115920.2053\n",
      "Epoch [15/20] Step [57/67] Loss 7942.9566\n",
      "Epoch [15/20] Step [58/67] Loss 38133.1957\n",
      "Epoch [15/20] Step [59/67] Loss 38645.4651\n",
      "Epoch [15/20] Step [60/67] Loss 21058.1972\n",
      "Epoch [15/20] Step [61/67] Loss 74037.4351\n",
      "Epoch [15/20] Step [62/67] Loss 37310.1512\n",
      "Epoch [15/20] Step [63/67] Loss 21762.9423\n",
      "Epoch [15/20] Step [64/67] Loss 24957.6958\n",
      "Epoch [15/20] Step [65/67] Loss 33838.5183\n",
      "Epoch [15/20] Step [66/67] Loss 36345.9922\n",
      "Epoch [16/20] Step [0/67] Loss 47043.0772\n",
      "Epoch [16/20] Step [1/67] Loss 66624.6272\n",
      "Epoch [16/20] Step [2/67] Loss 15714.5445\n",
      "Epoch [16/20] Step [3/67] Loss 12313.2052\n",
      "Epoch [16/20] Step [4/67] Loss 15032.9529\n",
      "Epoch [16/20] Step [5/67] Loss 15688.1464\n",
      "Epoch [16/20] Step [6/67] Loss 31867.9320\n",
      "Epoch [16/20] Step [7/67] Loss 76551.9637\n",
      "Epoch [16/20] Step [8/67] Loss 58825.1152\n",
      "Epoch [16/20] Step [9/67] Loss 63736.2983\n",
      "Epoch [16/20] Step [10/67] Loss 27754.5990\n",
      "Epoch [16/20] Step [11/67] Loss 71123.1993\n",
      "Epoch [16/20] Step [12/67] Loss 100272.3151\n",
      "Epoch [16/20] Step [13/67] Loss 50380.9537\n",
      "Epoch [16/20] Step [14/67] Loss 51458.8041\n",
      "Epoch [16/20] Step [15/67] Loss 39515.5882\n",
      "Epoch [16/20] Step [16/67] Loss 26842.9812\n",
      "Epoch [16/20] Step [17/67] Loss 29248.6805\n",
      "Epoch [16/20] Step [18/67] Loss 48430.6961\n",
      "Epoch [16/20] Step [19/67] Loss 33165.8143\n",
      "Epoch [16/20] Step [20/67] Loss 43733.2031\n",
      "Epoch [16/20] Step [21/67] Loss 32699.8237\n",
      "Epoch [16/20] Step [22/67] Loss 26632.0373\n",
      "Epoch [16/20] Step [23/67] Loss 94750.4345\n",
      "Epoch [16/20] Step [24/67] Loss 72061.7304\n",
      "Epoch [16/20] Step [25/67] Loss 14227.2323\n",
      "Epoch [16/20] Step [26/67] Loss 43845.4479\n",
      "Epoch [16/20] Step [27/67] Loss 112377.1819\n",
      "Epoch [16/20] Step [28/67] Loss 30033.7441\n",
      "Epoch [16/20] Step [29/67] Loss 92747.6430\n",
      "Epoch [16/20] Step [30/67] Loss 110160.4458\n",
      "Epoch [16/20] Step [31/67] Loss 53540.8452\n",
      "Epoch [16/20] Step [32/67] Loss 35376.1631\n",
      "Epoch [16/20] Step [33/67] Loss 17296.5960\n",
      "Epoch [16/20] Step [34/67] Loss 34721.0141\n",
      "Epoch [16/20] Step [35/67] Loss 25961.1512\n",
      "Epoch [16/20] Step [36/67] Loss 76537.1171\n",
      "Epoch [16/20] Step [37/67] Loss 53239.6794\n",
      "Epoch [16/20] Step [38/67] Loss 45549.2681\n",
      "Epoch [16/20] Step [39/67] Loss 71081.8059\n",
      "Epoch [16/20] Step [40/67] Loss 8431.5414\n",
      "Epoch [16/20] Step [41/67] Loss 28681.8721\n",
      "Epoch [16/20] Step [42/67] Loss 25047.6341\n",
      "Epoch [16/20] Step [43/67] Loss 8477.7970\n",
      "Epoch [16/20] Step [44/67] Loss 30857.5658\n",
      "Epoch [16/20] Step [45/67] Loss 107871.8330\n",
      "Epoch [16/20] Step [46/67] Loss 28607.5314\n",
      "Epoch [16/20] Step [47/67] Loss 22628.1370\n",
      "Epoch [16/20] Step [48/67] Loss 15491.7421\n",
      "Epoch [16/20] Step [49/67] Loss 155261.3718\n",
      "Epoch [16/20] Step [50/67] Loss 24824.1159\n",
      "Epoch [16/20] Step [51/67] Loss 42736.7283\n",
      "Epoch [16/20] Step [52/67] Loss 68512.3144\n",
      "Epoch [16/20] Step [53/67] Loss 109958.1823\n",
      "Epoch [16/20] Step [54/67] Loss 94293.2379\n",
      "Epoch [16/20] Step [55/67] Loss 18689.4039\n",
      "Epoch [16/20] Step [56/67] Loss 116674.4918\n",
      "Epoch [16/20] Step [57/67] Loss 8020.6385\n",
      "Epoch [16/20] Step [58/67] Loss 37712.7180\n",
      "Epoch [16/20] Step [59/67] Loss 38450.7464\n",
      "Epoch [16/20] Step [60/67] Loss 21040.2779\n",
      "Epoch [16/20] Step [61/67] Loss 73625.3193\n",
      "Epoch [16/20] Step [62/67] Loss 36785.6115\n",
      "Epoch [16/20] Step [63/67] Loss 21403.0896\n",
      "Epoch [16/20] Step [64/67] Loss 25312.7451\n",
      "Epoch [16/20] Step [65/67] Loss 34357.4464\n",
      "Epoch [16/20] Step [66/67] Loss 36617.8867\n",
      "Epoch [17/20] Step [0/67] Loss 47200.9080\n",
      "Epoch [17/20] Step [1/67] Loss 66813.4113\n",
      "Epoch [17/20] Step [2/67] Loss 15725.9308\n",
      "Epoch [17/20] Step [3/67] Loss 12426.0735\n",
      "Epoch [17/20] Step [4/67] Loss 15166.1699\n",
      "Epoch [17/20] Step [5/67] Loss 15608.8545\n",
      "Epoch [17/20] Step [6/67] Loss 31681.8145\n",
      "Epoch [17/20] Step [7/67] Loss 76533.5602\n",
      "Epoch [17/20] Step [8/67] Loss 58300.9271\n",
      "Epoch [17/20] Step [9/67] Loss 63157.2161\n",
      "Epoch [17/20] Step [10/67] Loss 27736.6312\n",
      "Epoch [17/20] Step [11/67] Loss 71568.1714\n",
      "Epoch [17/20] Step [12/67] Loss 99878.7169\n",
      "Epoch [17/20] Step [13/67] Loss 50336.3351\n",
      "Epoch [17/20] Step [14/67] Loss 50921.8353\n",
      "Epoch [17/20] Step [15/67] Loss 39955.7473\n",
      "Epoch [17/20] Step [16/67] Loss 26620.4611\n",
      "Epoch [17/20] Step [17/67] Loss 29696.4224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20] Step [18/67] Loss 47997.7555\n",
      "Epoch [17/20] Step [19/67] Loss 33292.4885\n",
      "Epoch [17/20] Step [20/67] Loss 43881.0851\n",
      "Epoch [17/20] Step [21/67] Loss 32781.7665\n",
      "Epoch [17/20] Step [22/67] Loss 26939.2808\n",
      "Epoch [17/20] Step [23/67] Loss 95154.9793\n",
      "Epoch [17/20] Step [24/67] Loss 72477.6244\n",
      "Epoch [17/20] Step [25/67] Loss 14356.6982\n",
      "Epoch [17/20] Step [26/67] Loss 44275.2969\n",
      "Epoch [17/20] Step [27/67] Loss 111711.0695\n",
      "Epoch [17/20] Step [28/67] Loss 30211.6533\n",
      "Epoch [17/20] Step [29/67] Loss 92061.9401\n",
      "Epoch [17/20] Step [30/67] Loss 110046.8082\n",
      "Epoch [17/20] Step [31/67] Loss 52998.8785\n",
      "Epoch [17/20] Step [32/67] Loss 34979.4689\n",
      "Epoch [17/20] Step [33/67] Loss 17235.2538\n",
      "Epoch [17/20] Step [34/67] Loss 34347.1233\n",
      "Epoch [17/20] Step [35/67] Loss 26331.9506\n",
      "Epoch [17/20] Step [36/67] Loss 75934.1803\n",
      "Epoch [17/20] Step [37/67] Loss 53782.0060\n",
      "Epoch [17/20] Step [38/67] Loss 45425.3890\n",
      "Epoch [17/20] Step [39/67] Loss 70451.8425\n",
      "Epoch [17/20] Step [40/67] Loss 8459.6995\n",
      "Epoch [17/20] Step [41/67] Loss 28321.1440\n",
      "Epoch [17/20] Step [42/67] Loss 24918.4763\n",
      "Epoch [17/20] Step [43/67] Loss 8508.9710\n",
      "Epoch [17/20] Step [44/67] Loss 31216.5794\n",
      "Epoch [17/20] Step [45/67] Loss 107119.6797\n",
      "Epoch [17/20] Step [46/67] Loss 28907.3163\n",
      "Epoch [17/20] Step [47/67] Loss 22782.9553\n",
      "Epoch [17/20] Step [48/67] Loss 15293.6802\n",
      "Epoch [17/20] Step [49/67] Loss 154483.5267\n",
      "Epoch [17/20] Step [50/67] Loss 25092.7540\n",
      "Epoch [17/20] Step [51/67] Loss 43045.5035\n",
      "Epoch [17/20] Step [52/67] Loss 67975.2053\n",
      "Epoch [17/20] Step [53/67] Loss 109656.4138\n",
      "Epoch [17/20] Step [54/67] Loss 93701.6897\n",
      "Epoch [17/20] Step [55/67] Loss 18976.0467\n",
      "Epoch [17/20] Step [56/67] Loss 117220.0305\n",
      "Epoch [17/20] Step [57/67] Loss 8078.1116\n",
      "Epoch [17/20] Step [58/67] Loss 37408.6618\n",
      "Epoch [17/20] Step [59/67] Loss 38312.4298\n",
      "Epoch [17/20] Step [60/67] Loss 21026.1502\n",
      "Epoch [17/20] Step [61/67] Loss 73327.7211\n",
      "Epoch [17/20] Step [62/67] Loss 36412.3570\n",
      "Epoch [17/20] Step [63/67] Loss 21147.1337\n",
      "Epoch [17/20] Step [64/67] Loss 25571.3308\n",
      "Epoch [17/20] Step [65/67] Loss 34733.7214\n",
      "Epoch [17/20] Step [66/67] Loss 36816.4486\n",
      "Epoch [18/20] Step [0/67] Loss 47319.5026\n",
      "Epoch [18/20] Step [1/67] Loss 66949.9184\n",
      "Epoch [18/20] Step [2/67] Loss 15737.9815\n",
      "Epoch [18/20] Step [3/67] Loss 12510.9436\n",
      "Epoch [18/20] Step [4/67] Loss 15265.9337\n",
      "Epoch [18/20] Step [5/67] Loss 15556.7908\n",
      "Epoch [18/20] Step [6/67] Loss 31555.5107\n",
      "Epoch [18/20] Step [7/67] Loss 76525.4902\n",
      "Epoch [18/20] Step [8/67] Loss 57926.4429\n",
      "Epoch [18/20] Step [9/67] Loss 62742.2603\n",
      "Epoch [18/20] Step [10/67] Loss 27728.1349\n",
      "Epoch [18/20] Step [11/67] Loss 71890.8886\n",
      "Epoch [18/20] Step [12/67] Loss 99596.2874\n",
      "Epoch [18/20] Step [13/67] Loss 50299.1111\n",
      "Epoch [18/20] Step [14/67] Loss 50536.9599\n",
      "Epoch [18/20] Step [15/67] Loss 40274.4134\n",
      "Epoch [18/20] Step [16/67] Loss 26464.0059\n",
      "Epoch [18/20] Step [17/67] Loss 30020.8203\n",
      "Epoch [18/20] Step [18/67] Loss 47687.7251\n",
      "Epoch [18/20] Step [19/67] Loss 33387.4919\n",
      "Epoch [18/20] Step [20/67] Loss 43992.1991\n",
      "Epoch [18/20] Step [21/67] Loss 32845.1754\n",
      "Epoch [18/20] Step [22/67] Loss 27162.8089\n",
      "Epoch [18/20] Step [23/67] Loss 95450.4386\n",
      "Epoch [18/20] Step [24/67] Loss 72777.6115\n",
      "Epoch [18/20] Step [25/67] Loss 14453.1794\n",
      "Epoch [18/20] Step [26/67] Loss 44585.6519\n",
      "Epoch [18/20] Step [27/67] Loss 111228.7828\n",
      "Epoch [18/20] Step [28/67] Loss 30340.7070\n",
      "Epoch [18/20] Step [29/67] Loss 91565.7862\n",
      "Epoch [18/20] Step [30/67] Loss 109965.6329\n",
      "Epoch [18/20] Step [31/67] Loss 52610.4476\n",
      "Epoch [18/20] Step [32/67] Loss 34695.7850\n",
      "Epoch [18/20] Step [33/67] Loss 17189.8867\n",
      "Epoch [18/20] Step [34/67] Loss 34081.4690\n",
      "Epoch [18/20] Step [35/67] Loss 26602.2285\n",
      "Epoch [18/20] Step [36/67] Loss 75499.3817\n",
      "Epoch [18/20] Step [37/67] Loss 54172.2856\n",
      "Epoch [18/20] Step [38/67] Loss 45337.6755\n",
      "Epoch [18/20] Step [39/67] Loss 69999.3044\n",
      "Epoch [18/20] Step [40/67] Loss 8480.3740\n",
      "Epoch [18/20] Step [41/67] Loss 28063.3914\n",
      "Epoch [18/20] Step [42/67] Loss 24830.5434\n",
      "Epoch [18/20] Step [43/67] Loss 8534.1830\n",
      "Epoch [18/20] Step [44/67] Loss 31475.0587\n",
      "Epoch [18/20] Step [45/67] Loss 106581.0130\n",
      "Epoch [18/20] Step [46/67] Loss 29124.5071\n",
      "Epoch [18/20] Step [47/67] Loss 22896.4936\n",
      "Epoch [18/20] Step [48/67] Loss 15153.7119\n",
      "Epoch [18/20] Step [49/67] Loss 153923.2725\n",
      "Epoch [18/20] Step [50/67] Loss 25287.7340\n",
      "Epoch [18/20] Step [51/67] Loss 43268.4151\n",
      "Epoch [18/20] Step [52/67] Loss 67591.9666\n",
      "Epoch [18/20] Step [53/67] Loss 109439.5839\n",
      "Epoch [18/20] Step [54/67] Loss 93276.5331\n",
      "Epoch [18/20] Step [55/67] Loss 19184.5525\n",
      "Epoch [18/20] Step [56/67] Loss 117614.6552\n",
      "Epoch [18/20] Step [57/67] Loss 8120.3157\n",
      "Epoch [18/20] Step [58/67] Loss 37188.5026\n",
      "Epoch [18/20] Step [59/67] Loss 38213.6154\n",
      "Epoch [18/20] Step [60/67] Loss 21015.0517\n",
      "Epoch [18/20] Step [61/67] Loss 73112.4656\n",
      "Epoch [18/20] Step [62/67] Loss 36145.5978\n",
      "Epoch [18/20] Step [63/67] Loss 20964.1186\n",
      "Epoch [18/20] Step [64/67] Loss 25759.1980\n",
      "Epoch [18/20] Step [65/67] Loss 35006.0928\n",
      "Epoch [18/20] Step [66/67] Loss 36961.1043\n",
      "Epoch [19/20] Step [0/67] Loss 47407.3418\n",
      "Epoch [19/20] Step [1/67] Loss 67048.5683\n",
      "Epoch [19/20] Step [2/67] Loss 15748.4994\n",
      "Epoch [19/20] Step [3/67] Loss 12573.8383\n",
      "Epoch [19/20] Step [4/67] Loss 15339.7089\n",
      "Epoch [19/20] Step [5/67] Loss 15521.9710\n",
      "Epoch [19/20] Step [6/67] Loss 31468.5056\n",
      "Epoch [19/20] Step [7/67] Loss 76522.3068\n",
      "Epoch [19/20] Step [8/67] Loss 57658.0685\n",
      "Epoch [19/20] Step [9/67] Loss 62444.1645\n",
      "Epoch [19/20] Step [10/67] Loss 27724.4962\n",
      "Epoch [19/20] Step [11/67] Loss 72124.7093\n",
      "Epoch [19/20] Step [12/67] Loss 99393.1720\n",
      "Epoch [19/20] Step [13/67] Loss 50269.1649\n",
      "Epoch [19/20] Step [14/67] Loss 50260.3690\n",
      "Epoch [19/20] Step [15/67] Loss 40504.9322\n",
      "Epoch [19/20] Step [16/67] Loss 26353.2021\n",
      "Epoch [19/20] Step [17/67] Loss 30255.7435\n",
      "Epoch [19/20] Step [18/67] Loss 47464.9512\n",
      "Epoch [19/20] Step [19/67] Loss 33457.9951\n",
      "Epoch [19/20] Step [20/67] Loss 44074.8683\n",
      "Epoch [19/20] Step [21/67] Loss 32893.3626\n",
      "Epoch [19/20] Step [22/67] Loss 27325.1986\n",
      "Epoch [19/20] Step [23/67] Loss 95665.8482\n",
      "Epoch [19/20] Step [24/67] Loss 72994.0776\n",
      "Epoch [19/20] Step [25/67] Loss 14524.5513\n",
      "Epoch [19/20] Step [26/67] Loss 44809.7344\n",
      "Epoch [19/20] Step [27/67] Loss 110879.0483\n",
      "Epoch [19/20] Step [28/67] Loss 30434.1150\n",
      "Epoch [19/20] Step [29/67] Loss 91206.1891\n",
      "Epoch [19/20] Step [30/67] Loss 109907.2523\n",
      "Epoch [19/20] Step [31/67] Loss 52331.2754\n",
      "Epoch [19/20] Step [32/67] Loss 34492.2366\n",
      "Epoch [19/20] Step [33/67] Loss 17156.1350\n",
      "Epoch [19/20] Step [34/67] Loss 33891.9709\n",
      "Epoch [19/20] Step [35/67] Loss 26798.9637\n",
      "Epoch [19/20] Step [36/67] Loss 75185.2633\n",
      "Epoch [19/20] Step [37/67] Loss 54453.2315\n",
      "Epoch [19/20] Step [38/67] Loss 45275.1571\n",
      "Epoch [19/20] Step [39/67] Loss 69673.4789\n",
      "Epoch [19/20] Step [40/67] Loss 8495.2936\n",
      "Epoch [19/20] Step [41/67] Loss 27878.6042\n",
      "Epoch [19/20] Step [42/67] Loss 24770.1109\n",
      "Epoch [19/20] Step [43/67] Loss 8553.8727\n",
      "Epoch [19/20] Step [44/67] Loss 31661.1856\n",
      "Epoch [19/20] Step [45/67] Loss 106194.3131\n",
      "Epoch [19/20] Step [46/67] Loss 29281.7199\n",
      "Epoch [19/20] Step [47/67] Loss 22979.4434\n",
      "Epoch [19/20] Step [48/67] Loss 15054.2728\n",
      "Epoch [19/20] Step [49/67] Loss 153519.1149\n",
      "Epoch [19/20] Step [50/67] Loss 25429.0788\n",
      "Epoch [19/20] Step [51/67] Loss 43429.3180\n",
      "Epoch [19/20] Step [52/67] Loss 67317.7165\n",
      "Epoch [19/20] Step [53/67] Loss 109283.4164\n",
      "Epoch [19/20] Step [54/67] Loss 92970.4095\n",
      "Epoch [19/20] Step [55/67] Loss 19335.9905\n",
      "Epoch [19/20] Step [56/67] Loss 117900.0829\n",
      "Epoch [19/20] Step [57/67] Loss 8151.1532\n",
      "Epoch [19/20] Step [58/67] Loss 37029.0367\n",
      "Epoch [19/20] Step [59/67] Loss 38142.7681\n",
      "Epoch [19/20] Step [60/67] Loss 21006.4441\n",
      "Epoch [19/20] Step [61/67] Loss 72956.7319\n",
      "Epoch [19/20] Step [62/67] Loss 35954.3818\n",
      "Epoch [19/20] Step [63/67] Loss 20832.8227\n",
      "Epoch [19/20] Step [64/67] Loss 25895.3941\n",
      "Epoch [19/20] Step [65/67] Loss 35202.9170\n",
      "Epoch [19/20] Step [66/67] Loss 37066.3031\n",
      "Epoch [20/20] Step [0/67] Loss 47471.6509\n",
      "Epoch [20/20] Step [1/67] Loss 67119.8966\n",
      "Epoch [20/20] Step [2/67] Loss 15756.8641\n",
      "Epoch [20/20] Step [3/67] Loss 12619.9352\n",
      "Epoch [20/20] Step [4/67] Loss 15393.7247\n",
      "Epoch [20/20] Step [5/67] Loss 15498.2867\n",
      "Epoch [20/20] Step [6/67] Loss 31407.7448\n",
      "Epoch [20/20] Step [7/67] Loss 76521.2683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20] Step [8/67] Loss 57465.4027\n",
      "Epoch [20/20] Step [9/67] Loss 62229.7081\n",
      "Epoch [20/20] Step [10/67] Loss 27723.2620\n",
      "Epoch [20/20] Step [11/67] Loss 72293.9385\n",
      "Epoch [20/20] Step [12/67] Loss 99246.9312\n",
      "Epoch [20/20] Step [13/67] Loss 50245.7345\n",
      "Epoch [20/20] Step [14/67] Loss 50061.2822\n",
      "Epoch [20/20] Step [15/67] Loss 40671.5978\n",
      "Epoch [20/20] Step [16/67] Loss 26274.2966\n",
      "Epoch [20/20] Step [17/67] Loss 30425.8220\n",
      "Epoch [20/20] Step [18/67] Loss 47304.5062\n",
      "Epoch [20/20] Step [19/67] Loss 33509.9307\n",
      "Epoch [20/20] Step [20/67] Loss 44135.9267\n",
      "Epoch [20/20] Step [21/67] Loss 32929.5231\n",
      "Epoch [20/20] Step [22/67] Loss 27443.0810\n",
      "Epoch [20/20] Step [23/67] Loss 95822.7164\n",
      "Epoch [20/20] Step [24/67] Loss 73150.3546\n",
      "Epoch [20/20] Step [25/67] Loss 14577.0792\n",
      "Epoch [20/20] Step [26/67] Loss 44971.5715\n",
      "Epoch [20/20] Step [27/67] Loss 110625.0994\n",
      "Epoch [20/20] Step [28/67] Loss 30501.6083\n",
      "Epoch [20/20] Step [29/67] Loss 90945.2300\n",
      "Epoch [20/20] Step [30/67] Loss 109865.0828\n",
      "Epoch [20/20] Step [31/67] Loss 52130.2123\n",
      "Epoch [20/20] Step [32/67] Loss 34345.8529\n",
      "Epoch [20/20] Step [33/67] Loss 17130.9290\n",
      "Epoch [20/20] Step [34/67] Loss 33756.4158\n",
      "Epoch [20/20] Step [35/67] Loss 26942.0151\n",
      "Epoch [20/20] Step [36/67] Loss 74958.0701\n",
      "Epoch [20/20] Step [37/67] Loss 54655.5535\n",
      "Epoch [20/20] Step [38/67] Loss 45230.3763\n",
      "Epoch [20/20] Step [39/67] Loss 69438.5154\n",
      "Epoch [20/20] Step [40/67] Loss 8505.9020\n",
      "Epoch [20/20] Step [41/67] Loss 27745.8359\n",
      "Epoch [20/20] Step [42/67] Loss 24728.2856\n",
      "Epoch [20/20] Step [43/67] Loss 8568.9164\n",
      "Epoch [20/20] Step [44/67] Loss 31795.2699\n",
      "Epoch [20/20] Step [45/67] Loss 105916.1578\n",
      "Epoch [20/20] Step [46/67] Loss 29395.4881\n",
      "Epoch [20/20] Step [47/67] Loss 23039.8776\n",
      "Epoch [20/20] Step [48/67] Loss 14983.3082\n",
      "Epoch [20/20] Step [49/67] Loss 153227.2193\n",
      "Epoch [20/20] Step [50/67] Loss 25531.4808\n",
      "Epoch [20/20] Step [51/67] Loss 43545.4783\n",
      "Epoch [20/20] Step [52/67] Loss 67120.9577\n",
      "Epoch [20/20] Step [53/67] Loss 109170.7404\n",
      "Epoch [20/20] Step [54/67] Loss 92749.6472\n",
      "Epoch [20/20] Step [55/67] Loss 19445.8811\n",
      "Epoch [20/20] Step [56/67] Loss 118106.5659\n",
      "Epoch [20/20] Step [57/67] Loss 8173.6275\n",
      "Epoch [20/20] Step [58/67] Loss 36913.5354\n",
      "Epoch [20/20] Step [59/67] Loss 38091.8510\n",
      "Epoch [20/20] Step [60/67] Loss 20999.8832\n",
      "Epoch [20/20] Step [61/67] Loss 72844.0873\n",
      "Epoch [20/20] Step [62/67] Loss 35817.0016\n",
      "Epoch [20/20] Step [63/67] Loss 20738.3759\n",
      "Epoch [20/20] Step [64/67] Loss 25993.9622\n",
      "Epoch [20/20] Step [65/67] Loss 35344.9606\n",
      "Epoch [20/20] Step [66/67] Loss 37142.7244\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "print_every = 1000\n",
    "clip = 5\n",
    "counter = 0\n",
    "valid_loss_min = np.Inf\n",
    "batch_size = 1\n",
    "\n",
    "model.zero_grad()\n",
    "optimizer.zero_grad()\n",
    "model.train()\n",
    "for epoch in range(epochs+1):\n",
    "    (h, c) = model.init_hidden(BATCH_SIZE)\n",
    "    for step, (inputs, expected) in enumerate(dataloader):\n",
    "        counter += 1\n",
    "        inputs = inputs.to(device)\n",
    "        expected = inputs.to(device)\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        h.detach_()\n",
    "        c.detach_()\n",
    "        output, (h, c) = model(inputs.float(), (h,c))\n",
    "        loss = criterion(output.double(), expected.double())\n",
    "        \n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        print('Epoch [{}/{}] Step [{}/{}] Loss {:.4f}'.format(epoch, epochs, step, len(dataloader), loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 250, 26])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = dataloader[0][0]\n",
    "frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "frame1 = dataloader[45][0][0].reshape(1, 250, 26)\n",
    "stath, statc = model.init_hidden(1)\n",
    "stath.to(device)\n",
    "statc.to(device)\n",
    "output, (shh, scc) = model(frame1.to(device), (stath, statc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = from_numpy_vector_to_motion_coordinates(output[0]).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_points(from_numpy_vector_to_motion_coordinates(frame1[0])[58])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
