{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C-RNN-GAN\n",
    "http://mogren.one/publications/2016/c-rnn-gan/mogren2016crnngan.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available, CPU used\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, features, hidden_size):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.features = features\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=(features*2), out_features=hidden_size)\n",
    "        self.lstm1 = nn.LSTMCell(input_size=hidden_size, hidden_size=hidden_size)\n",
    "        self.dropout = nn.Dropout(p=0.6)\n",
    "        self.lstm2 = nn.LSTMCell(input_size=hidden_size, hidden_size=hidden_size)\n",
    "        self.fc2 = nn.Linear(in_features=hidden_size, out_features=features)\n",
    "        \n",
    "    def forward(self, z, states):\n",
    "        z = z.to(device)\n",
    "        batch_size, seq_len, num_feats = z.shape\n",
    "        z = torch.split(z, 1, dim=1)\n",
    "        z = [z_step.squeeze(dim=1) for z_step in z]\n",
    "        \n",
    "        prev_gen = torch.empty([batch_size, num_feats]).uniform_()\n",
    "        prev_gen = prev_gen.to(device)\n",
    "        \n",
    "        state1, state2 = states\n",
    "        gen_feats = []\n",
    "        for z_step in z:\n",
    "            concat_in = torch.cat((z_step, prev_gen), dim=-1)\n",
    "            out = F.relu(self.fc1(concat_in))\n",
    "            h1, c1 = self.lstm1(out, state1)\n",
    "            h1 = self.dropout(h1)\n",
    "            h2, c2 = self.lstm2(h1, state2)\n",
    "            prev_gen = self.fc2(h2)\n",
    "            gen_feats.append(prev_gen)\n",
    "            state1 = (h1, c1)\n",
    "            state2 = (h2, c2)\n",
    "        \n",
    "        # seq_len * (batch_size * num_feats) -> (batch_size * seq_len * num_feats)\n",
    "        gen_feats = torch.stack(gen_feats, dim=1)\n",
    "        \n",
    "        states = (state1, state2)\n",
    "        return gen_feats, states\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        hidden = ( (weight.new(batch_size, self.hidden_size).zero_().to(device),\n",
    "                   weight.new(batch_size, self.hidden_size).zero_().to(device)),\n",
    "                   (weight.new(batch_size, self.hidden_size).zero_().to(device),\n",
    "                   weight.new(batch_size, self.hidden_size).zero_().to(device)) )\n",
    "\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmodel = Generator(13, 100).to(device)\n",
    "dmodel = Discriminator(13, 100).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "g_states = gmodel.init_hidden(BATCH_SIZE)\n",
    "d_state = dmodel.init_hidden(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq = torch.arange(13. * 4.).reshape(1, 4, 13).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmodel.eval()\n",
    "g_feats, _ = gmodel(input_seq, g_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, features, hidden_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = 2\n",
    "        self.dropout = nn.Dropout(p=.5)\n",
    "        self.lstm = nn.LSTM(input_size=features, hidden_size=hidden_size,\n",
    "                           num_layers=self.num_layers, batch_first=True, dropout=0.5,\n",
    "                           bidirectional=True)\n",
    "    \n",
    "        self.fc = nn.Linear(in_features=(2*hidden_size), out_features=1)\n",
    "        \n",
    "    def forward(self, sequence, state):\n",
    "        sequence = sequence.to(device)\n",
    "        drop_in = self.dropout(sequence)\n",
    "        \n",
    "        lstm_out, state = self.lstm(drop_in, state)\n",
    "        out = self.fc(lstm_out)\n",
    "        out = torch.sigmoid(out)\n",
    "        \n",
    "        num_dims = len(out.shape)\n",
    "        reduction_dims = tuple(range(1, num_dims))\n",
    "        out = torch.mean(out, dim=reduction_dims)\n",
    "        \n",
    "        return out, lstm_out, state\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        layer_mult = 2\n",
    "        \n",
    "        hidden = (weight.new(self.num_layers * layer_mult, batch_size, self.hidden_size).zero_().to(device),\n",
    "                 weight.new(self.num_layers * layer_mult, batch_size, self.hidden_size).zero_().to(device))\n",
    "        \n",
    "        return hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_logits_gen, _, _ = dmodel(g_feats, d_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
