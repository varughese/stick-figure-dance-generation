{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C-RNN-GAN\n",
    "http://mogren.one/publications/2016/c-rnn-gan/mogren2016crnngan.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "# https://github.com/cjbayron/c-rnn-gan.pytorch/blob/master/train_simple.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available, CPU used\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, features, hidden_size):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.features = features\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=(features*2), out_features=hidden_size)\n",
    "        self.lstm1 = nn.LSTMCell(input_size=hidden_size, hidden_size=hidden_size)\n",
    "        self.dropout = nn.Dropout(p=0.6)\n",
    "        self.lstm2 = nn.LSTMCell(input_size=hidden_size, hidden_size=hidden_size)\n",
    "        self.fc2 = nn.Linear(in_features=hidden_size, out_features=features)\n",
    "        \n",
    "    def forward(self, z, states):\n",
    "        z = z.to(device)\n",
    "        batch_size, seq_len, num_feats = z.shape\n",
    "        z = torch.split(z, 1, dim=1)\n",
    "        z = [z_step.squeeze(dim=1) for z_step in z]\n",
    "        \n",
    "        prev_gen = torch.empty([batch_size, num_feats]).uniform_()\n",
    "        prev_gen = prev_gen.to(device)\n",
    "        \n",
    "        state1, state2 = states\n",
    "        gen_feats = []\n",
    "        for z_step in z:\n",
    "            concat_in = torch.cat((z_step, prev_gen), dim=-1)\n",
    "            out = F.relu(self.fc1(concat_in))\n",
    "            h1, c1 = self.lstm1(out, state1)\n",
    "            h1 = self.dropout(h1)\n",
    "            h2, c2 = self.lstm2(h1, state2)\n",
    "            prev_gen = self.fc2(h2)\n",
    "            gen_feats.append(prev_gen)\n",
    "            state1 = (h1, c1)\n",
    "            state2 = (h2, c2)\n",
    "        \n",
    "        # seq_len * (batch_size * num_feats) -> (batch_size * seq_len * num_feats)\n",
    "        gen_feats = torch.stack(gen_feats, dim=1)\n",
    "        \n",
    "        states = (state1, state2)\n",
    "        return gen_feats, states\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        hidden = ( (weight.new(batch_size, self.hidden_size).zero_().to(device),\n",
    "                   weight.new(batch_size, self.hidden_size).zero_().to(device)),\n",
    "                   (weight.new(batch_size, self.hidden_size).zero_().to(device),\n",
    "                   weight.new(batch_size, self.hidden_size).zero_().to(device)) )\n",
    "\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, features, hidden_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = 2\n",
    "        self.dropout = nn.Dropout(p=.5)\n",
    "        self.lstm = nn.LSTM(input_size=features, hidden_size=hidden_size,\n",
    "                           num_layers=self.num_layers, batch_first=True, dropout=0.5,\n",
    "                           bidirectional=True)\n",
    "    \n",
    "        self.fc = nn.Linear(in_features=(2*hidden_size), out_features=1)\n",
    "        \n",
    "    def forward(self, sequence, state):\n",
    "        sequence = sequence.to(device)\n",
    "        drop_in = self.dropout(sequence)\n",
    "        \n",
    "        lstm_out, state = self.lstm(drop_in, state)\n",
    "        out = self.fc(lstm_out)\n",
    "        out = torch.sigmoid(out)\n",
    "        \n",
    "        num_dims = len(out.shape)\n",
    "        reduction_dims = tuple(range(1, num_dims))\n",
    "        out = torch.mean(out, dim=reduction_dims)\n",
    "        \n",
    "        return out, lstm_out, state\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        layer_mult = 2\n",
    "        \n",
    "        hidden = (weight.new(self.num_layers * layer_mult, batch_size, self.hidden_size).zero_().to(device),\n",
    "                 weight.new(self.num_layers * layer_mult, batch_size, self.hidden_size).zero_().to(device))\n",
    "        \n",
    "        return hidden\n",
    "\n",
    "class DLoss(nn.Module):\n",
    "    ''' C-RNN-GAN discriminator loss\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(DLoss, self).__init__()\n",
    "\n",
    "    def forward(self, logits_real, logits_gen):\n",
    "        ''' Discriminator loss\n",
    "        logits_real: logits from D, when input is real\n",
    "        logits_gen: logits from D, when input is from Generator\n",
    "        '''\n",
    "        logits_real = torch.clamp(logits_real, EPSILON, 1.0)\n",
    "        d_loss_real = -torch.log(logits_real)\n",
    "\n",
    "        logits_gen = torch.clamp((1 - logits_gen), EPSILON, 1.0)\n",
    "        d_loss_gen = -torch.log(logits_gen)\n",
    "\n",
    "        batch_loss = d_loss_real + d_loss_gen\n",
    "        return torch.mean(batch_loss)\n",
    "\n",
    "def control_grad(model, freeze=True):\n",
    "    ''' Freeze/unfreeze optimization of model\n",
    "    '''\n",
    "    if freeze:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    else: # unfreeze\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "    \n",
    "def check_loss(model, loss):\n",
    "    ''' Check loss and control gradients if necessary\n",
    "    '''\n",
    "    control_grad(model['g'], freeze=False)\n",
    "    control_grad(model['d'], freeze=False)\n",
    "\n",
    "    if loss['d'] == 0.0 and loss['g'] == 0.0:\n",
    "        print('Both G and D train loss are zero. Exiting.')\n",
    "        return False\n",
    "    elif loss['d'] == 0.0: # freeze D\n",
    "        control_grad(model['d'], freeze=True)\n",
    "    elif loss['g'] == 0.0: # freeze G\n",
    "        control_grad(model['g'], freeze=True)\n",
    "    elif loss['g'] < 2.0 or loss['d'] < 2.0:\n",
    "        control_grad(model['d'], freeze=True)\n",
    "        if loss['g']*0.7 > loss['d']:\n",
    "            control_grad(model['g'], freeze=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training, trying to output numbers with the function `f(n) = 2*f(n-1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import optim\n",
    "npdata = np.stack([2 ** np.arange(10)[:, np.newaxis] * np.random.rand() for i in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  0.2647],\n",
       "         [  0.5293],\n",
       "         [  1.0587],\n",
       "         [  2.1174],\n",
       "         [  4.2348],\n",
       "         [  8.4695],\n",
       "         [ 16.9391],\n",
       "         [ 33.8782],\n",
       "         [ 67.7564],\n",
       "         [135.5128]], dtype=torch.float64),)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = TensorDataset(torch.from_numpy(npdata))\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(data, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " [tensor([[[0.0064],\n",
       "           [0.0129],\n",
       "           [0.0258],\n",
       "           [0.0515],\n",
       "           [0.1030],\n",
       "           [0.2060],\n",
       "           [0.4120],\n",
       "           [0.8241],\n",
       "           [1.6482],\n",
       "           [3.2964]]], dtype=torch.float64)])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(dataloader))[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each element of data loader is a sequence. Thats it We just put this into a function to make a train set and validation set easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-8240059b46f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    print(batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-cb7c62ab834b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "for batch, in dataloader:\n",
    "    print(batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_dataloader(seq_len, batch_size, num_sample):\n",
    "    ''' Dummy data generator (for debugging purposes)\n",
    "    '''\n",
    "    # the following code generates random data of numbers\n",
    "    # where each number is twice the prev number\n",
    "    np_data = np.stack([(2 ** np.arange(seq_len))[:, np.newaxis] \\\n",
    "                        * np.random.rand() for i in range(num_sample)])\n",
    "\n",
    "    data = TensorDataset(torch.from_numpy(np_data))\n",
    "    return DataLoader(data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 20\n",
    "trn_dataloader = dummy_dataloader(MAX_SEQ_LEN, 13, 7)\n",
    "val_dataloader = dummy_dataloader(MAX_SEQ_LEN, 13, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = {\n",
    "    'g': Generator(features=1, hidden_size=100),\n",
    "    'd': Discriminator(features=1, hidden_size=100)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_states = model['g'].init_hidden(real_batch_sz)\n",
    "d_state = model['d'].init_hidden(real_batch_sz)\n",
    "z = torch.empty([100, MAX_SEQ_LEN, 1]).uniform_()\n",
    "real_batch_sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input batch size 100 doesn't match hidden[0] batch size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-e0e9e66f43ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mg_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'g'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-bd0f924e0ce8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, z, states)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mconcat_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcat_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mh1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mh1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mh2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    937\u001b[0m             \u001b[0mzeros\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 939\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'[0]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    940\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'[1]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m         return _VF.lstm_cell(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_hidden\u001b[0;34m(self, input, hx, hidden_label)\u001b[0m\n\u001b[1;32m    766\u001b[0m             raise RuntimeError(\n\u001b[1;32m    767\u001b[0m                 \"Input batch size {} doesn't match hidden{} batch size {}\".format(\n\u001b[0;32m--> 768\u001b[0;31m                     input.size(0), hidden_label, hx.size(0)))\n\u001b[0m\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input batch size 100 doesn't match hidden[0] batch size 1"
     ]
    }
   ],
   "source": [
    "g_feats, _ = model['g'](z, g_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_LRN_RATE = 0.001\n",
    "D_LRN_RATE = 0.001\n",
    "PERFORM_LOSS_CHECKING = True\n",
    "MAX_GRAD_NORM = 5.0\n",
    "MAX_EPOCHS = 500\n",
    "L2_DECAY = 1.0\n",
    "\n",
    "optimizer = {\n",
    "    'g': optim.Adam(model['g'].parameters(), G_LRN_RATE),\n",
    "    'd': optim.Adam(model['d'].parameters(), D_LRN_RATE)\n",
    "}\n",
    "criterion = {\n",
    "    'g': nn.MSELoss(reduction='sum'),\n",
    "    'd': DLoss()\n",
    "}\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "freeze_g = False\n",
    "freeze_d = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training] G_loss: %0.8f, D_loss: %0.8f, D_acc: %0.2f 0.0 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1, 20, 200])) that is different to the input size (torch.Size([1, 10, 200])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (10) must match the size of tensor b (20) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-b7b5ec67a781>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;31m# calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'g'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_feats_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_feats_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'd'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_logits_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_logits_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2209\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2211\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2212\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreduction\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'none'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2213\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreduction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mean'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (10) must match the size of tensor b (20) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    # TRAINING\n",
    "    loss = {\n",
    "        'g': 10.0,\n",
    "        'd': 10.0\n",
    "    }\n",
    "    \n",
    "    features = model['g'].features\n",
    "    model['g'].train()\n",
    "    model['d'].train()\n",
    "\n",
    "    g_loss_total = 0.0\n",
    "    d_loss_total = 0.0\n",
    "    num_corrects = 0\n",
    "    num_sample = 0\n",
    "\n",
    "    log_sum_real = 0.0\n",
    "    log_sum_gen = 0.0\n",
    "    \n",
    "    for (batch_input, ) in dataloader:\n",
    "        real_batch_sz = len(batch_input)\n",
    "        batch_input = batch_input.type(torch.FloatTensor)\n",
    "        \n",
    "        if PERFORM_LOSS_CHECKING == True:\n",
    "            if not check_loss(model, loss):\n",
    "                break\n",
    "        \n",
    "        g_states = model['g'].init_hidden(real_batch_sz)\n",
    "        d_state = model['d'].init_hidden(real_batch_sz)\n",
    "        \n",
    "        ### GENERATOR ###\n",
    "        if not freeze_g:\n",
    "            optimizer['g'].zero_grad()\n",
    "            \n",
    "        z = torch.empty([real_batch_sz, MAX_SEQ_LEN, features]).uniform_()\n",
    "        \n",
    "        g_feats, _ = model['g'](z, g_states)\n",
    "        _, d_feats_real, _ = model['d'](batch_input, d_state)\n",
    "        _, d_feats_gen, _ = model['d'](g_feats, d_state)\n",
    "        \n",
    "        loss['g'] = criterion['g'](d_feats_real, d_feats_gen)\n",
    "        if not freeze_g:\n",
    "            loss['g'].backward()\n",
    "            # nn.utils.clip_grad_norm_(model['g'].parameters(), max_norm=MAX_GRAD_NORM)\n",
    "            optimizer['g'].step()\n",
    "\n",
    "        #### DISCRIMINATOR ####\n",
    "        if not freeze_d:\n",
    "            optimizer['d'].zero_grad()\n",
    "        \n",
    "        \n",
    "        d_logits_real, _, _ = model['d'](batch_input, d_state)\n",
    "        d_logits_gen, _, _ = model['d'](g_feats.detach(), d_state)\n",
    "        \n",
    "        loss['d'] = criterion['d'](d_logits_real, d_logits_gen)\n",
    "        \n",
    "        log_sum_real += d_logits_real.sum().item()\n",
    "        log_sum_gen += d_logits_gen.sum().item()\n",
    "        \n",
    "        if not freeze_d:\n",
    "            loss['d'].backward()\n",
    "            nn.utils.clip_grad_norm_(model['d'].parameters(), max_norm=MAX_GRAD_NORM)\n",
    "            optimizer['d'].step()\n",
    "            \n",
    "        g_loss_total += loss['g'].item()\n",
    "        d_loss_total += loss['d'].item()\n",
    "        num_corrects += (d_logits_real > 0.5).sum().item() + (d_logits_gen < 0.5).sum().item()\n",
    "        num_sample += real_batch_sz\n",
    "        \n",
    "    g_loss_avg, d_loss_avg = 0.0, 0.0\n",
    "    d_acc = 0.0\n",
    "    if num_sample > 0:\n",
    "        g_loss_avg = g_loss_total / num_sample\n",
    "        d_loss_avg = d_loss_total / num_sample\n",
    "        d_acc = 100 * num_corrects / (2 * num_sample) # 2 because (real + generated)\n",
    "\n",
    "        print(\"Trn: \", log_sum_real / num_sample, log_sum_gen / num_sample)\n",
    "\n",
    "    print(\"[Training] G_loss: %0.8f, D_loss: %0.8f, D_acc: %0.2f\", g_loss_avg, d_loss_avg, d_acc)\n",
    "    \n",
    "\n",
    "    # VALIDATE\n",
    "    model['g'].eval()\n",
    "    model['d'].eval()\n",
    "    \n",
    "    g_loss_total = 0.0\n",
    "    d_loss_total = 0.0\n",
    "    num_corrects = 0\n",
    "    num_sample = 0\n",
    "\n",
    "    log_sum_real = 0.0\n",
    "    log_sum_gen = 0.0\n",
    "\n",
    "    for (batch_input, ) in dataloader:\n",
    "\n",
    "        real_batch_sz = len(batch_input)\n",
    "        batch_input = batch_input.type(torch.FloatTensor)\n",
    "\n",
    "        # initial states\n",
    "        g_states = model['g'].init_hidden(real_batch_sz)\n",
    "        d_state = model['d'].init_hidden(real_batch_sz)\n",
    "\n",
    "        #### GENERATOR ####\n",
    "        # prepare inputs\n",
    "        z = torch.empty([real_batch_sz, MAX_SEQ_LEN, features]).uniform_() # random vector\n",
    "\n",
    "        # feed inputs to generator\n",
    "        g_feats, _ = model['g'](z, g_states)\n",
    "        # feed real and generated input to discriminator\n",
    "        d_logits_real, d_feats_real, _ = model['d'](batch_input, d_state)\n",
    "        d_logits_gen, d_feats_gen, _ = model['d'](g_feats, d_state)\n",
    "        # print(\"Val: \", d_logits_real.mean(), d_logits_gen.mean())\n",
    "        log_sum_real += d_logits_real.sum().item()\n",
    "        log_sum_gen += d_logits_gen.sum().item()\n",
    "\n",
    "        # calculate loss\n",
    "        g_loss = criterion['g'](d_feats_real, d_feats_gen)\n",
    "        d_loss = criterion['d'](d_logits_real, d_logits_gen)\n",
    "\n",
    "        g_loss_total += g_loss.item()\n",
    "        d_loss_total += d_loss.item()\n",
    "        num_corrects += (d_logits_real > 0.5).sum().item() + (d_logits_gen < 0.5).sum().item()\n",
    "        num_sample += real_batch_sz\n",
    "\n",
    "    g_loss_avg, d_loss_avg = 0.0, 0.0\n",
    "    d_acc = 0.0\n",
    "    if num_sample > 0:\n",
    "        g_loss_avg = g_loss_total / num_sample\n",
    "        d_loss_avg = d_loss_total / num_sample\n",
    "        d_acc = 100 * num_corrects / (2 * num_sample) # 2 because (real + generated)\n",
    "\n",
    "        print(\"Val: \", log_sum_real / num_sample, log_sum_gen / num_sample)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
